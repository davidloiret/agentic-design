import { Technique } from './types';

export const exceptionHandlingRecoveryTechniques: Technique[] = [
  {
    id: 'circuit-breaker',
    name: 'Circuit Breaker Pattern',
    abbr: 'CBP',
    icon: 'âš¡',
    color: 'from-red-500 to-orange-600',
    category: 'exception-handling-recovery',
    description: 'Prevents cascade failures by temporarily stopping calls to failing services and allowing recovery',
    features: [
      'Failure threshold detection',
      'Automatic recovery testing',
      'State management (Open/Closed/Half-Open)',
      'Fallback mechanisms',
      'Performance monitoring',
      'Adaptive timeout handling'
    ],
    useCases: ['microservices', 'api-integration', 'distributed-systems', 'fault-tolerance'],
    complexity: 'medium',
    example: 'AI Model Service Circuit Breaker:\n\nCircuit States:\n\n1. Closed (Normal Operation):\n   â€¢ All requests pass through\n   â€¢ Success rate: 98.5%\n   â€¢ Latency: 120ms average\n   â€¢ Monitoring: Continuous failure tracking\n\n2. Open (Failure State):\n   â€¢ Trigger: 5 failures in 30 seconds\n   â€¢ Action: Block all requests for 60 seconds\n   â€¢ Fallback: Use cached responses or simpler model\n   â€¢ Status: "Service temporarily unavailable"\n\n3. Half-Open (Recovery Testing):\n   â€¢ Duration: After 60-second timeout\n   â€¢ Test requests: Allow 3 trial requests\n   â€¢ Success threshold: 2/3 must succeed\n   â€¢ Decision: Return to Closed or back to Open\n\nImplementation:\n\n```python\nclass AIModelCircuitBreaker:\n    def __init__(self):\n        self.failure_threshold = 5\n        self.recovery_timeout = 60\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = "CLOSED"\n    \n    def call_ai_model(self, request):\n        if self.state == "OPEN":\n            if self._should_attempt_reset():\n                self.state = "HALF_OPEN"\n            else:\n                return self._fallback_response()\n        \n        try:\n            result = ai_model.predict(request)\n            self._on_success()\n            return result\n        except Exception as e:\n            self._on_failure()\n            return self._fallback_response()\n```\n\nBenefits:\nâ€¢ Prevented 12 cascade failures last month\nâ€¢ 99.7% uptime vs 94.2% without circuit breaker\nâ€¢ Automatic recovery in 95% of cases\nâ€¢ User experience: Graceful degradation instead of errors'
  },
  {
    id: 'retry-backoff',
    name: 'Intelligent Retry with Backoff',
    abbr: 'IRB',
    icon: 'ðŸ”„',
    color: 'from-orange-500 to-yellow-600',
    category: 'exception-handling-recovery',
    description: 'Smart retry mechanisms with exponential backoff and jitter to handle transient failures gracefully',
    features: [
      'Exponential backoff strategy',
      'Jitter randomization',
      'Retry limit configuration',
      'Error classification',
      'Idempotency handling',
      'Success rate optimization'
    ],
    useCases: ['api-calls', 'database-operations', 'network-requests', 'distributed-processing'],
    complexity: 'medium',
    example: 'LLM API Retry Strategy:\n\nError Classification:\n\n1. Retryable Errors:\n   â€¢ Network timeouts (503, 504)\n   â€¢ Rate limiting (429)\n   â€¢ Temporary service unavailable (503)\n   â€¢ Internal server errors (500)\n\n2. Non-Retryable Errors:\n   â€¢ Authentication failures (401, 403)\n   â€¢ Invalid requests (400)\n   â€¢ Not found (404)\n   â€¢ Quota exceeded (permanent)\n\nRetry Configuration:\nâ€¢ Max attempts: 5\nâ€¢ Base delay: 1 second\nâ€¢ Max delay: 30 seconds\nâ€¢ Backoff multiplier: 2\nâ€¢ Jitter: Â±25% randomization\n\nExecution Example:\n\nAttempt 1: Immediate request\nâ€¢ Result: 429 Rate Limit\nâ€¢ Next delay: 1s + jitter (0.8-1.2s)\n\nAttempt 2: After 1.1s delay\nâ€¢ Result: 503 Service Unavailable\nâ€¢ Next delay: 2s + jitter (1.5-2.5s)\n\nAttempt 3: After 2.2s delay\nâ€¢ Result: Timeout\nâ€¢ Next delay: 4s + jitter (3-5s)\n\nAttempt 4: After 4.7s delay\nâ€¢ Result: 200 Success\nâ€¢ Total time: 8.0s (vs immediate failure)\n\nSmart Optimizations:\n\n1. Context-Aware Delays:\n   â€¢ Rate limits: Respect Retry-After header\n   â€¢ Server errors: Longer delays\n   â€¢ Network issues: Shorter delays\n\n2. Adaptive Backoff:\n   â€¢ Success rate < 50%: Increase base delay\n   â€¢ Success rate > 90%: Decrease base delay\n   â€¢ Peak hours: Add traffic-aware delays\n\n3. Request Classification:\n   â€¢ Critical requests: More retries\n   â€¢ Batch operations: Fewer retries\n   â€¢ User-facing: Fast timeout\n\nResults:\nâ€¢ Success rate: 94.2% â†’ 98.7%\nâ€¢ User-perceived errors: -78%\nâ€¢ Average latency: +2.3s (acceptable trade-off)\nâ€¢ Cost efficiency: Reduced duplicate processing'
  },
  {
    id: 'graceful-degradation',
    name: 'Graceful Degradation',
    abbr: 'GD',
    icon: 'ðŸ“‰',
    color: 'from-yellow-500 to-green-600',
    category: 'exception-handling-recovery',
    description: 'Progressive reduction of functionality while maintaining core services during system stress or failures',
    features: [
      'Priority-based feature disabling',
      'Resource allocation optimization',
      'Quality level adjustment',
      'User experience preservation',
      'Automatic scaling decisions',
      'Recovery monitoring'
    ],
    useCases: ['high-availability', 'resource-management', 'peak-load-handling', 'disaster-recovery'],
    complexity: 'high',
    example: 'AI-Powered E-commerce Degradation:\n\nService Priority Levels:\n\n1. Critical (Always Available):\n   â€¢ User authentication\n   â€¢ Order placement\n   â€¢ Payment processing\n   â€¢ Basic product search\n\n2. Important (Degrade Quality):\n   â€¢ Personalized recommendations\n   â€¢ Advanced search filters\n   â€¢ Product image analysis\n   â€¢ Customer support chat\n\n3. Nice-to-Have (Disable First):\n   â€¢ AI styling suggestions\n   â€¢ Voice search\n   â€¢ AR try-on features\n   â€¢ Social sharing\n\nDegradation Scenario:\n\nNormal Load (100% capacity):\nâ€¢ All features enabled\nâ€¢ High-quality AI recommendations\nâ€¢ Real-time personalization\nâ€¢ Full search capabilities\n\nModerate Stress (80% capacity):\nâ€¢ Reduce recommendation quality\nâ€¢ Cache more responses\nâ€¢ Simplify search ranking\nâ€¢ Batch non-critical operations\n\nHigh Stress (60% capacity):\nâ€¢ Disable AR features\nâ€¢ Use pre-computed recommendations\nâ€¢ Basic search only\nâ€¢ Queue customer support\n\nCritical Stress (40% capacity):\nâ€¢ Disable AI styling\nâ€¢ Show popular items only\nâ€¢ Essential checkout flow\nâ€¢ Static content where possible\n\nImplementation Strategy:\n\n1. Real-time Monitoring:\n   â€¢ CPU/Memory utilization\n   â€¢ Request queue length\n   â€¢ Response time percentiles\n   â€¢ Error rates by service\n\n2. Automatic Triggers:\n   â€¢ P95 latency > 2s: Level 1 degradation\n   â€¢ Error rate > 5%: Level 2 degradation\n   â€¢ Queue > 1000: Level 3 degradation\n   â€¢ Infrastructure alerts: Level 4 degradation\n\n3. User Communication:\n   â€¢ Subtle feature disabling (no error messages)\n   â€¢ Status page for major degradations\n   â€¢ Estimated recovery times\n   â€¢ Alternative workflow suggestions\n\nRecovery Process:\nâ€¢ Gradual re-enabling of features\nâ€¢ Performance validation at each level\nâ€¢ Rollback if issues reoccur\nâ€¢ Post-incident analysis\n\nResults:\nâ€¢ 99.95% uptime vs 97.2% without degradation\nâ€¢ Revenue protection: $2.3M saved during incidents\nâ€¢ User satisfaction: 94% vs 76% during outages\nâ€¢ Recovery time: 67% faster than full restoration'
  },
  {
    id: 'health-monitoring',
    name: 'Comprehensive Health Monitoring',
    abbr: 'CHM',
    icon: 'ðŸ’“',
    color: 'from-green-500 to-blue-600',
    category: 'exception-handling-recovery',
    description: 'Multi-layered health monitoring system with predictive failure detection and automated recovery',
    features: [
      'Multi-metric health scoring',
      'Predictive failure analysis',
      'Automated alerting',
      'Dependency tracking',
      'Performance trend analysis',
      'Self-healing mechanisms'
    ],
    useCases: ['production-monitoring', 'predictive-maintenance', 'sla-management', 'automated-recovery'],
    complexity: 'high',
    example: 'AI Model Serving Health Monitor:\n\nHealth Dimensions:\n\n1. Performance Health (Weight: 30%):\n   â€¢ Latency: P95 < 500ms (Current: 340ms) âœ…\n   â€¢ Throughput: >1000 req/min (Current: 1,450) âœ…\n   â€¢ Success rate: >99% (Current: 99.7%) âœ…\n   â€¢ Score: 95/100\n\n2. Resource Health (Weight: 25%):\n   â€¢ CPU utilization: <80% (Current: 72%) âœ…\n   â€¢ Memory usage: <85% (Current: 78%) âœ…\n   â€¢ GPU memory: <90% (Current: 84%) âœ…\n   â€¢ Disk I/O: Normal (Current: 45 IOPS) âœ…\n   â€¢ Score: 88/100\n\n3. Quality Health (Weight: 25%):\n   â€¢ Model accuracy: >95% (Current: 96.2%) âœ…\n   â€¢ Output coherence: >90% (Current: 94%) âœ…\n   â€¢ Safety violations: <0.1% (Current: 0.03%) âœ…\n   â€¢ User satisfaction: >4.0 (Current: 4.3) âœ…\n   â€¢ Score: 96/100\n\n4. Infrastructure Health (Weight: 20%):\n   â€¢ Network connectivity: Stable âœ…\n   â€¢ Database response: <100ms (Current: 67ms) âœ…\n   â€¢ Cache hit rate: >80% (Current: 87%) âœ…\n   â€¢ Load balancer: Healthy âœ…\n   â€¢ Score: 92/100\n\nOverall Health Score: 93/100 (Healthy)\n\nPredictive Analysis:\n\n1. Trend Detection:\n   â€¢ Memory usage: +2% per day (concerning)\n   â€¢ Prediction: Will exceed threshold in 6 days\n   â€¢ Action: Schedule memory optimization\n\n2. Anomaly Detection:\n   â€¢ Latency spike detected at 2:15 PM\n   â€¢ Correlation: Database connection pool exhaustion\n   â€¢ Auto-remedy: Pool size increased\n   â€¢ Resolution time: 45 seconds\n\n3. Dependency Health:\n   â€¢ External API: 94% availability (below SLA)\n   â€¢ Impact: Fallback mechanisms activated\n   â€¢ Mitigation: Secondary provider routing\n\nAutomated Recovery Actions:\n\n1. Self-Healing Triggers:\n   â€¢ Memory leak detected â†’ Container restart\n   â€¢ High latency â†’ Load balancer adjustment\n   â€¢ Model drift â†’ Automatic retraining trigger\n   â€¢ Cache miss spike â†’ Preload popular queries\n\n2. Escalation Procedures:\n   â€¢ Health score < 80: Alert on-call engineer\n   â€¢ Health score < 60: Page entire team\n   â€¢ Critical failure: Activate incident response\n\n3. Recovery Validation:\n   â€¢ Health score improvement verification\n   â€¢ Performance metric stabilization\n   â€¢ User impact assessment\n   â€¢ Documentation of recovery actions\n\nBusiness Impact:\nâ€¢ Incident prevention: 23 issues auto-resolved\nâ€¢ MTTR reduction: 78% faster recovery\nâ€¢ Uptime improvement: 99.92% vs 98.7%\nâ€¢ Cost savings: $450K in prevented downtime'
  }
];