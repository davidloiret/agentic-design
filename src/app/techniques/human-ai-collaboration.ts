import { Technique } from './types';

export const humanAiCollaborationTechniques: Technique[] = [
  {
    id: 'human-in-the-loop',
    name: 'Human-in-the-Loop',
    abbr: 'HITL',
    icon: 'üë§',
    color: 'from-blue-500 to-indigo-600',
    category: 'human-ai-collaboration',
    description: 'Strategic integration of human judgment at critical decision points in AI workflows',
    features: [
      'Strategic human intervention points',
      'Confidence-based escalation',
      'Human expertise integration',
      'Quality assurance checkpoints',
      'Feedback loop optimization',
      'Domain expert validation'
    ],
    useCases: ['medical-diagnosis', 'legal-analysis', 'financial-decisions', 'content-moderation', 'safety-critical-systems'],
    complexity: 'medium',
    example: 'Medical Imaging Analysis:\n\n1. AI Analysis:\n   ‚Ä¢ Scans chest X-ray\n   ‚Ä¢ Detects potential abnormality (78% confidence)\n   ‚Ä¢ Flags for human review (threshold: 80%)\n\n2. Human Intervention:\n   ‚Ä¢ Radiologist reviews flagged case\n   ‚Ä¢ Confirms suspicious mass in upper left lobe\n   ‚Ä¢ Adds contextual notes: "Consider CT follow-up"\n\n3. Collaborative Decision:\n   ‚Ä¢ AI + Human consensus: "Abnormal finding requiring further investigation"\n   ‚Ä¢ Confidence increased to 95%\n   ‚Ä¢ Automatic scheduling of follow-up CT\n\nBenefits:\n‚Ä¢ AI handles routine cases (85% of volume)\n‚Ä¢ Human expertise for complex/uncertain cases\n‚Ä¢ Continuous learning from human feedback\n‚Ä¢ Maintains final human accountability'
  },
  {
    id: 'human-on-the-loop',
    name: 'Human On the Loop',
    abbr: 'HOTL',
    icon: 'üëÅÔ∏è',
    color: 'from-cyan-500 to-blue-600',
    category: 'human-ai-collaboration',
    description: 'Human supervisory oversight of autonomous AI systems with ability to monitor, intervene, or take control when necessary',
    features: [
      'Continuous monitoring and observation',
      'Exception-based intervention',
      'Override and takeover capabilities',
      'Performance monitoring dashboards',
      'Automated alert systems',
      'Supervisory control interfaces'
    ],
    useCases: ['autonomous-vehicles', 'trading-systems', 'manufacturing-automation', 'air-traffic-control', 'process-monitoring'],
    complexity: 'high',
    example: 'Autonomous Trading System:\n\nNormal Operation (Human On the Loop):\n\n1. AI Trading Activity:\n   ‚Ä¢ Executes 1,200 trades per hour automatically\n   ‚Ä¢ Follows programmed strategies and risk parameters\n   ‚Ä¢ Maintains portfolio within defined risk limits\n   ‚Ä¢ Performance: +2.3% daily return\n\n2. Human Monitoring:\n   ‚Ä¢ Trader monitors via real-time dashboard\n   ‚Ä¢ Watches key metrics: P&L, volume, risk exposure\n   ‚Ä¢ Reviews automated alerts and warnings\n   ‚Ä¢ No intervention needed - system operating normally\n\n3. Exception Scenario:\n   ‚Ä¢ Market volatility spikes unexpectedly\n   ‚Ä¢ AI system detects unusual market conditions\n   ‚Ä¢ Automated alert: "High volatility detected - review recommended"\n   ‚Ä¢ Risk exposure approaching upper limit\n\n4. Human Intervention:\n   ‚Ä¢ Trader reviews situation in 30 seconds\n   ‚Ä¢ Decides market conditions are too volatile\n   ‚Ä¢ Takes manual control: "Override - reduce position size by 50%"\n   ‚Ä¢ AI continues with new human-set parameters\n\n5. Return to Autonomy:\n   ‚Ä¢ Market conditions stabilize after 2 hours\n   ‚Ä¢ Trader approves return to full autonomous operation\n   ‚Ä¢ AI resumes normal trading with lessons learned\n\nMonitoring Features:\n‚Ä¢ Real-time performance dashboard\n‚Ä¢ Configurable alert thresholds\n‚Ä¢ One-click intervention capabilities\n‚Ä¢ Audit trail of all human interventions\n‚Ä¢ Automated reporting and analysis\n\nBenefits:\n‚Ä¢ Enables high-speed autonomous operation\n‚Ä¢ Human expertise available when needed\n‚Ä¢ Reduces human workload (95% autonomous time)\n‚Ä¢ Maintains ultimate human control and accountability\n‚Ä¢ Allows humans to focus on strategic decisions'
  },
  {
    id: 'human-ai-team-formation',
    name: 'Human-AI Team Formation',
    abbr: 'HATF',
    icon: 'ü§ù',
    color: 'from-indigo-500 to-purple-600',
    category: 'human-ai-collaboration',
    description: 'Dynamic formation of mixed human-AI teams based on task requirements and expertise',
    features: [
      'Dynamic team composition',
      'Expertise-based matching',
      'Role specialization',
      'Complementary skill pairing',
      'Adaptive team restructuring',
      'Performance-based optimization'
    ],
    useCases: ['research-projects', 'creative-work', 'complex-analysis', 'innovation-labs', 'consulting-teams'],
    complexity: 'high',
    example: 'Market Research Project:\n\nTask: "Analyze emerging trends in sustainable packaging"\n\nTeam Formation Algorithm:\n1. Skill Requirements Analysis:\n   ‚Ä¢ Data analysis: High\n   ‚Ä¢ Domain expertise: Medium\n   ‚Ä¢ Creative synthesis: High\n   ‚Ä¢ Technical writing: Medium\n\n2. Optimal Team Composition:\n   ‚Ä¢ AI Agent: Data Mining Specialist\n     - Processes 10K+ industry reports\n     - Identifies statistical patterns\n     - Generates quantitative insights\n   \n   ‚Ä¢ Human Expert: Sustainability Consultant\n     - 15 years packaging industry experience\n     - Validates AI findings\n     - Provides strategic context\n   \n   ‚Ä¢ AI Agent: Creative Synthesis AI\n     - Combines insights from multiple sources\n     - Generates innovative concepts\n     - Creates presentation materials\n\n3. Collaboration Workflow:\n   ‚Ä¢ Phase 1: AI data collection + Human validation\n   ‚Ä¢ Phase 2: Joint analysis and interpretation\n   ‚Ä¢ Phase 3: AI synthesis + Human strategic review\n\nResult: 40% faster project completion with higher quality insights'
  },
  {
    id: 'augmented-decision-making',
    name: 'Augmented Decision Making',
    abbr: 'ADM',
    icon: 'üéØ',
    color: 'from-purple-500 to-pink-600',
    category: 'human-ai-collaboration',
    description: 'AI enhances human decision-making by providing data-driven insights and scenario analysis',
    features: [
      'Real-time insight provision',
      'Scenario simulation',
      'Risk assessment integration',
      'Decision support visualization',
      'Bias detection and mitigation',
      'Outcome prediction modeling'
    ],
    useCases: ['strategic-planning', 'investment-decisions', 'policy-making', 'clinical-decisions', 'business-strategy'],
    complexity: 'high',
    example: 'Investment Portfolio Decision:\n\nHuman Goal: "Rebalance portfolio for 2024 market conditions"\n\nAI Augmentation:\n1. Market Analysis:\n   ‚Ä¢ Processes 50K+ financial data points\n   ‚Ä¢ Identifies: Tech sector volatility ‚Üë15%, Energy sector stability ‚Üë8%\n   ‚Ä¢ Predicts: Interest rate impact on REITs\n\n2. Scenario Modeling:\n   ‚Ä¢ Scenario A (40% probability): Continued inflation\n     ‚Üí Recommend: Gold +5%, Tech -10%\n   ‚Ä¢ Scenario B (35% probability): Economic stability  \n     ‚Üí Recommend: Maintain current allocation\n   ‚Ä¢ Scenario C (25% probability): Market correction\n     ‚Üí Recommend: Cash +15%, Defensive stocks +8%\n\n3. Risk Assessment:\n   ‚Ä¢ Current portfolio risk: 7.2/10\n   ‚Ä¢ Proposed adjustments reduce risk to 5.8/10\n   ‚Ä¢ Maintains expected return within 2% of target\n\n4. Human Decision Process:\n   ‚Ä¢ Reviews AI analysis and scenarios\n   ‚Ä¢ Adds personal risk tolerance (moderate)\n   ‚Ä¢ Considers life circumstances (approaching retirement)\n   ‚Ä¢ Final decision: Blend of Scenario A & C recommendations\n\nOutcome: Data-informed decision with human judgment and personal context'
  },
  {
    id: 'collaborative-learning',
    name: 'Collaborative Learning',
    abbr: 'CL',
    icon: 'üìö',
    color: 'from-pink-500 to-red-600',
    category: 'human-ai-collaboration',
    description: 'Continuous mutual learning between humans and AI systems to improve performance over time',
    features: [
      'Bidirectional knowledge transfer',
      'Incremental skill development',
      'Feedback-driven improvement',
      'Adaptive learning rates',
      'Knowledge gap identification',
      'Performance co-evolution'
    ],
    useCases: ['personalized-education', 'skill-development', 'research-collaboration', 'creative-projects', 'professional-training'],
    complexity: 'high',
    example: 'Legal Research Collaboration:\n\nWeek 1 - Initial State:\n‚Ä¢ AI: Strong at case law search, weak at legal strategy\n‚Ä¢ Lawyer: Expert in strategy, slower at document review\n\nCollaborative Learning Process:\n\n1. AI Learning from Human:\n   ‚Ä¢ Lawyer explains why certain precedents are more relevant\n   ‚Ä¢ AI learns strategic thinking patterns: "Constitutional cases trump statutory when fundamental rights involved"\n   ‚Ä¢ Updates weighting algorithms based on lawyer feedback\n\n2. Human Learning from AI:\n   ‚Ä¢ AI identifies overlooked case: "Smith v. Jones (2019) - similar fact pattern"\n   ‚Ä¢ Lawyer discovers new legal research strategies\n   ‚Ä¢ Adopts AI\'s systematic approach to citation analysis\n\n3. Mutual Improvement:\n   ‚Ä¢ AI develops better legal reasoning (strategy accuracy: 65% ‚Üí 78%)\n   ‚Ä¢ Lawyer increases research efficiency (time per case: 4h ‚Üí 2.5h)\n   ‚Ä¢ Together they discover novel legal arguments\n\nWeek 12 Results:\n‚Ä¢ Case success rate improved 23%\n‚Ä¢ Research time reduced 40%\n‚Ä¢ Both human and AI capabilities enhanced\n‚Ä¢ New hybrid legal strategies developed\n\nKey Success Factors:\n‚Ä¢ Regular feedback exchange\n‚Ä¢ Shared performance metrics\n‚Ä¢ Complementary strength recognition\n‚Ä¢ Trust building over time'
  },
  {
    id: 'explainable-ai-interaction',
    name: 'Explainable AI Interaction',
    abbr: 'XAI',
    icon: 'üí°',
    color: 'from-red-500 to-orange-600',
    category: 'human-ai-collaboration',
    description: 'AI systems that can explain their reasoning and decisions to human collaborators',
    features: [
      'Natural language explanations',
      'Visual reasoning displays',
      'Interactive exploration tools',
      'Confidence level communication',
      'Alternative pathway showing',
      'Uncertainty transparency'
    ],
    useCases: ['scientific-research', 'medical-diagnosis', 'judicial-decisions', 'financial-analysis', 'educational-tools'],
    complexity: 'high',
    example: 'Drug Discovery Research:\n\nAI Recommendation: "Compound X-47 shows 78% probability of success for treating Type 2 diabetes"\n\nExplainable Interaction:\n\n1. High-Level Explanation:\n   "I recommend X-47 because it has structural similarity to successful diabetes drugs and shows favorable molecular interactions with insulin receptors."\n\n2. Detailed Reasoning (on request):\n   ‚Ä¢ Molecular Structure Analysis:\n     - 87% similarity to Metformin (known effective drug)\n     - Contains glucose-binding motif found in 6/8 successful compounds\n   \n   ‚Ä¢ Biological Pathway Analysis:\n     - Targets AMPK pathway (validated for diabetes)\n     - Low off-target effects predicted (toxicity risk: 12%)\n   \n   ‚Ä¢ Historical Data Correlation:\n     - Similar compounds: 71% Phase II success rate\n     - Better safety profile than current alternatives\n\n3. Interactive Exploration:\n   Human: "What if we modify the benzene ring?"\n   AI: "Modifying position 4 increases potency 15% but raises toxicity to 18%. Position 6 modification maintains safety with 8% potency gain."\n\n4. Uncertainty Communication:\n   ‚Ä¢ Confidence breakdown:\n     - Efficacy prediction: 78% ¬± 12%\n     - Safety prediction: 85% ¬± 8%\n     - Market viability: 65% ¬± 20%\n   ‚Ä¢ Key uncertainties: Long-term effects, drug interactions\n\n5. Alternative Options:\n   "Second choice: Compound Y-23 (72% success probability, higher safety margin)"\n\nBenefits:\n‚Ä¢ Builds scientist trust through transparency\n‚Ä¢ Enables informed human decision-making\n‚Ä¢ Accelerates research through guided exploration\n‚Ä¢ Maintains human oversight in critical decisions'
  },
  {
    id: 'approval-workflows',
    name: 'Approval Workflows',
    abbr: 'AW',
    icon: '‚úÖ',
    color: 'from-green-500 to-emerald-600',
    category: 'human-ai-collaboration',
    description: 'Structured approval processes where human reviewers validate and approve AI-generated outputs or decisions',
    features: [
      'Multi-stage approval processes',
      'Role-based review assignments',
      'Automated routing and escalation',
      'Audit trails and documentation',
      'Conditional approval workflows',
      'Batch processing capabilities'
    ],
    useCases: ['content-publishing', 'financial-transactions', 'medical-decisions', 'legal-documents', 'policy-changes'],
    complexity: 'medium',
    example: 'Content Publishing Workflow:\n\nAI Content Generation:\n‚Ä¢ AI creates blog post draft: "10 Tips for Remote Work Productivity"\n‚Ä¢ Content quality score: 8.2/10\n‚Ä¢ SEO optimization: 85% complete\n‚Ä¢ Brand alignment: 92% match\n\nApproval Workflow:\n1. Tier 1 Review (Content Editor):\n   ‚Ä¢ Reviews for grammar, style, accuracy\n   ‚Ä¢ Checks brand voice consistency\n   ‚Ä¢ Decision: Approved with minor edits\n   ‚Ä¢ Time: 15 minutes\n\n2. Tier 2 Review (Subject Matter Expert):\n   ‚Ä¢ Validates technical accuracy of productivity tips\n   ‚Ä¢ Confirms practical applicability\n   ‚Ä¢ Decision: Approved\n   ‚Ä¢ Time: 10 minutes\n\n3. Final Review (Marketing Manager):\n   ‚Ä¢ Strategic alignment check\n   ‚Ä¢ Publication timing approval\n   ‚Ä¢ Decision: Approved for immediate publication\n   ‚Ä¢ Time: 5 minutes\n\nWorkflow Features:\n‚Ä¢ Parallel reviews where possible\n‚Ä¢ Automatic escalation for rejections\n‚Ä¢ Version control and change tracking\n‚Ä¢ Performance metrics for review times\n\nResult: High-quality, brand-aligned content published with full human oversight in 30 minutes'
  },
  {
    id: 'collaborative-filtering',
    name: 'Collaborative Filtering',
    abbr: 'CF',
    icon: 'üîç',
    color: 'from-blue-500 to-cyan-600',
    category: 'human-ai-collaboration',
    description: 'Human-AI collaborative approach to filtering, ranking, and curating content or decisions based on combined judgments',
    features: [
      'Human-AI preference alignment',
      'Collaborative ranking systems',
      'Learning from human feedback',
      'Quality score combination',
      'Bias detection and correction',
      'Iterative improvement cycles'
    ],
    useCases: ['content-curation', 'recommendation-systems', 'talent-screening', 'research-prioritization', 'risk-assessment'],
    complexity: 'high',
    example: 'Research Paper Curation:\n\nTask: Curate top 20 papers on "sustainable energy storage" from 500 candidates\n\nCollaborative Filtering Process:\n\n1. AI Initial Filtering:\n   ‚Ä¢ Semantic relevance scoring (0-1.0)\n   ‚Ä¢ Citation impact analysis\n   ‚Ä¢ Recency weighting (2020-2024)\n   ‚Ä¢ Technical quality indicators\n   ‚Ä¢ Reduces 500 papers to 100 candidates\n\n2. Human Expert Review:\n   ‚Ä¢ Domain expert reviews AI shortlist\n   ‚Ä¢ Adds domain-specific criteria:\n     - Commercial viability potential\n     - Environmental impact significance\n     - Technical feasibility assessment\n   ‚Ä¢ Flags 3 highly relevant papers AI missed\n   ‚Ä¢ Removes 15 papers with technical issues AI couldn\'t detect\n\n3. Collaborative Scoring:\n   ‚Ä¢ AI technical metrics: 40% weight\n   ‚Ä¢ Human domain expertise: 35% weight\n   ‚Ä¢ Combined impact prediction: 25% weight\n   ‚Ä¢ Final ranking incorporates both perspectives\n\n4. Iterative Refinement:\n   ‚Ä¢ Human feedback trains AI on domain preferences\n   ‚Ä¢ AI learns to weight technical vs. practical factors\n   ‚Ä¢ System improves with each curation cycle\n\nFinal Curation:\n‚Ä¢ 20 high-quality papers selected\n‚Ä¢ Balanced technical rigor and practical relevance\n‚Ä¢ 90% expert satisfaction rate\n‚Ä¢ 30% time reduction vs. manual curation\n\nBenefits:\n‚Ä¢ Combines AI scale with human domain expertise\n‚Ä¢ Learns and improves from collaboration\n‚Ä¢ Reduces expert workload while maintaining quality\n‚Ä¢ Provides explainable curation decisions'
  },
  {
    id: 'escalation-procedures',
    name: 'Escalation Procedures',
    abbr: 'EP',
    icon: 'üö®',
    color: 'from-orange-500 to-red-600',
    category: 'human-ai-collaboration',
    description: 'Systematic protocols for escalating AI decisions to appropriate human experts when confidence is low or stakes are high',
    features: [
      'Confidence-based escalation triggers',
      'Role-based expert routing',
      'Priority level assignment',
      'Escalation path optimization',
      'Response time guarantees',
      'Fallback mechanisms'
    ],
    useCases: ['customer-support', 'medical-triage', 'fraud-detection', 'content-moderation', 'crisis-management'],
    complexity: 'medium',
    example: 'Customer Support Escalation:\n\nCustomer Query: "My payment was charged twice and I need a refund immediately for rent money"\n\nEscalation Analysis:\n‚Ä¢ Query complexity: High (financial dispute)\n‚Ä¢ Emotional urgency: High (rent payment)\n‚Ä¢ AI confidence: Low (65% - ambiguous transaction details)\n‚Ä¢ Customer tier: Premium (5+ year customer)\n\nEscalation Decision Tree:\n\n1. Trigger Assessment:\n   ‚Ä¢ Low AI confidence (< 70%): ‚úì Escalate\n   ‚Ä¢ High emotional distress: ‚úì Escalate\n   ‚Ä¢ Financial impact > $200: ‚úì Escalate\n   ‚Ä¢ Premium customer: ‚úì Priority escalation\n\n2. Expert Routing:\n   ‚Ä¢ Issue type: Financial dispute ‚Üí Billing specialist\n   ‚Ä¢ Customer tier: Premium ‚Üí Senior agent\n   ‚Ä¢ Urgency: High ‚Üí Within 15 minutes\n   ‚Ä¢ Complexity: High ‚Üí Team lead backup\n\n3. Escalation Execution:\n   ‚Ä¢ Route to: Sarah (Senior Billing Specialist)\n   ‚Ä¢ Priority: High (15-minute SLA)\n   ‚Ä¢ Context package: Customer history, transaction logs, AI analysis\n   ‚Ä¢ Backup: Team Lead Mike (if Sarah unavailable)\n\n4. Resolution:\n   ‚Ä¢ Human expert resolves in 12 minutes\n   ‚Ä¢ Duplicate charge confirmed and refunded\n   ‚Ä¢ Customer satisfaction: 9/10\n   ‚Ä¢ AI learns from expert\'s decision process\n\nEscalation Metrics:\n‚Ä¢ 94% on-time expert engagement\n‚Ä¢ 87% first-contact resolution after escalation\n‚Ä¢ 4.2/5 average customer satisfaction\n‚Ä¢ AI confidence improves by learning from escalations\n\nBenefits:\n‚Ä¢ Ensures complex issues get expert attention\n‚Ä¢ Maintains high customer satisfaction\n‚Ä¢ Protects company from high-risk decisions\n‚Ä¢ Continuously improves AI through expert feedback'
  },
  {
    id: 'feedback-loops',
    name: 'Feedback Loops',
    abbr: 'FL',
    icon: 'üîÑ',
    color: 'from-purple-500 to-indigo-600',
    category: 'human-ai-collaboration',
    description: 'Systematic mechanisms for collecting, processing, and incorporating human feedback to continuously improve AI performance',
    features: [
      'Multi-channel feedback collection',
      'Real-time learning integration',
      'Feedback quality assessment',
      'Automated model updates',
      'Performance impact tracking',
      'Bias detection through feedback'
    ],
    useCases: ['personalization-systems', 'content-recommendation', 'search-optimization', 'predictive-models', 'user-interfaces'],
    complexity: 'high',
    example: 'E-commerce Recommendation System:\n\nContinuous Improvement Through Human Feedback:\n\n1. Feedback Collection:\n   ‚Ä¢ Explicit feedback: Star ratings, thumbs up/down\n   ‚Ä¢ Implicit feedback: Click-through rates, purchase behavior\n   ‚Ä¢ Contextual feedback: "Not interested in this category"\n   ‚Ä¢ Temporal feedback: Seasonal preference changes\n\n2. Feedback Processing:\n   ‚Ä¢ Week 1: 10,000 user interactions collected\n   ‚Ä¢ Positive signals: 6,200 (62%)\n   ‚Ä¢ Negative signals: 2,300 (23%)\n   ‚Ä¢ Neutral/ignored: 1,500 (15%)\n   ‚Ä¢ Quality score: High (low spam/fake feedback)\n\n3. Learning Integration:\n   ‚Ä¢ Real-time updates: Immediate personalization adjustments\n   ‚Ä¢ Batch learning: Weekly model retraining\n   ‚Ä¢ A/B testing: 10% traffic for new model validation\n   ‚Ä¢ Bias monitoring: Demographic fairness checks\n\n4. Performance Impact:\n   ‚Ä¢ Baseline metrics (Month 1):\n     - Click-through rate: 3.2%\n     - Conversion rate: 1.8%\n     - User satisfaction: 6.7/10\n   \n   ‚Ä¢ After feedback integration (Month 3):\n     - Click-through rate: 4.1% (+28%)\n     - Conversion rate: 2.4% (+33%)\n     - User satisfaction: 7.9/10 (+18%)\n\n5. Continuous Monitoring:\n   ‚Ä¢ Daily feedback volume tracking\n   ‚Ä¢ Weekly performance metric reviews\n   ‚Ä¢ Monthly bias and fairness audits\n   ‚Ä¢ Quarterly user satisfaction surveys\n\nFeedback Loop Features:\n‚Ä¢ Multi-granular: Product, category, and system-level feedback\n‚Ä¢ Adaptive: Learning rates adjust based on feedback confidence\n‚Ä¢ Transparent: Users see how their feedback improves recommendations\n‚Ä¢ Ethical: Privacy-preserving feedback processing\n\nResult: Self-improving recommendation system that gets better with use, achieving 33% higher conversion rates through systematic human-AI collaboration'
  }
]; 