import { Technique } from './types';

export const humanAiCollaborationTechniques: Technique[] = [
  {
    id: 'human-in-the-loop',
    name: 'Human-in-the-Loop',
    abbr: 'HITL',
    icon: 'üë§',
    color: 'from-blue-500 to-indigo-600',
    category: 'human-ai-collaboration',
    description: 'Strategic integration of human judgment at critical decision points in AI workflows',
    features: [
      'Strategic human intervention points',
      'Confidence-based escalation',
      'Human expertise integration',
      'Quality assurance checkpoints',
      'Feedback loop optimization',
      'Domain expert validation'
    ],
    useCases: ['medical-diagnosis', 'legal-analysis', 'financial-decisions', 'content-moderation', 'safety-critical-systems'],
    complexity: 'medium',
    example: 'Medical Imaging Analysis:\n\n1. AI Analysis:\n   ‚Ä¢ Scans chest X-ray\n   ‚Ä¢ Detects potential abnormality (78% confidence)\n   ‚Ä¢ Flags for human review (threshold: 80%)\n\n2. Human Intervention:\n   ‚Ä¢ Radiologist reviews flagged case\n   ‚Ä¢ Confirms suspicious mass in upper left lobe\n   ‚Ä¢ Adds contextual notes: "Consider CT follow-up"\n\n3. Collaborative Decision:\n   ‚Ä¢ AI + Human consensus: "Abnormal finding requiring further investigation"\n   ‚Ä¢ Confidence increased to 95%\n   ‚Ä¢ Automatic scheduling of follow-up CT\n\nBenefits:\n‚Ä¢ AI handles routine cases (85% of volume)\n‚Ä¢ Human expertise for complex/uncertain cases\n‚Ä¢ Continuous learning from human feedback\n‚Ä¢ Maintains final human accountability'
  },
  {
    id: 'human-on-the-loop',
    name: 'Human On the Loop',
    abbr: 'HOTL',
    icon: 'üëÅÔ∏è',
    color: 'from-cyan-500 to-blue-600',
    category: 'human-ai-collaboration',
    description: 'Human supervisory oversight of autonomous AI systems with ability to monitor, intervene, or take control when necessary',
    features: [
      'Continuous monitoring and observation',
      'Exception-based intervention',
      'Override and takeover capabilities',
      'Performance monitoring dashboards',
      'Automated alert systems',
      'Supervisory control interfaces'
    ],
    useCases: ['autonomous-vehicles', 'trading-systems', 'manufacturing-automation', 'air-traffic-control', 'process-monitoring'],
    complexity: 'high',
    example: 'Autonomous Trading System:\n\nNormal Operation (Human On the Loop):\n\n1. AI Trading Activity:\n   ‚Ä¢ Executes 1,200 trades per hour automatically\n   ‚Ä¢ Follows programmed strategies and risk parameters\n   ‚Ä¢ Maintains portfolio within defined risk limits\n   ‚Ä¢ Performance: +2.3% daily return\n\n2. Human Monitoring:\n   ‚Ä¢ Trader monitors via real-time dashboard\n   ‚Ä¢ Watches key metrics: P&L, volume, risk exposure\n   ‚Ä¢ Reviews automated alerts and warnings\n   ‚Ä¢ No intervention needed - system operating normally\n\n3. Exception Scenario:\n   ‚Ä¢ Market volatility spikes unexpectedly\n   ‚Ä¢ AI system detects unusual market conditions\n   ‚Ä¢ Automated alert: "High volatility detected - review recommended"\n   ‚Ä¢ Risk exposure approaching upper limit\n\n4. Human Intervention:\n   ‚Ä¢ Trader reviews situation in 30 seconds\n   ‚Ä¢ Decides market conditions are too volatile\n   ‚Ä¢ Takes manual control: "Override - reduce position size by 50%"\n   ‚Ä¢ AI continues with new human-set parameters\n\n5. Return to Autonomy:\n   ‚Ä¢ Market conditions stabilize after 2 hours\n   ‚Ä¢ Trader approves return to full autonomous operation\n   ‚Ä¢ AI resumes normal trading with lessons learned\n\nMonitoring Features:\n‚Ä¢ Real-time performance dashboard\n‚Ä¢ Configurable alert thresholds\n‚Ä¢ One-click intervention capabilities\n‚Ä¢ Audit trail of all human interventions\n‚Ä¢ Automated reporting and analysis\n\nBenefits:\n‚Ä¢ Enables high-speed autonomous operation\n‚Ä¢ Human expertise available when needed\n‚Ä¢ Reduces human workload (95% autonomous time)\n‚Ä¢ Maintains ultimate human control and accountability\n‚Ä¢ Allows humans to focus on strategic decisions'
  },
  {
    id: 'collaborative-learning',
    name: 'Collaborative Learning',
    abbr: 'CL',
    icon: 'üìö',
    color: 'from-pink-500 to-red-600',
    category: 'human-ai-collaboration',
    description: 'Continuous mutual learning between humans and AI systems to improve performance over time',
    features: [
      'Bidirectional knowledge transfer',
      'Incremental skill development',
      'Feedback-driven improvement',
      'Adaptive learning rates',
      'Knowledge gap identification',
      'Performance co-evolution'
    ],
    useCases: ['personalized-education', 'skill-development', 'research-collaboration', 'creative-projects', 'professional-training'],
    complexity: 'high',
    example: 'Legal Research Collaboration:\n\nWeek 1 - Initial State:\n‚Ä¢ AI: Strong at case law search, weak at legal strategy\n‚Ä¢ Lawyer: Expert in strategy, slower at document review\n\nCollaborative Learning Process:\n\n1. AI Learning from Human:\n   ‚Ä¢ Lawyer explains why certain precedents are more relevant\n   ‚Ä¢ AI learns strategic thinking patterns: "Constitutional cases trump statutory when fundamental rights involved"\n   ‚Ä¢ Updates weighting algorithms based on lawyer feedback\n\n2. Human Learning from AI:\n   ‚Ä¢ AI identifies overlooked case: "Smith v. Jones (2019) - similar fact pattern"\n   ‚Ä¢ Lawyer discovers new legal research strategies\n   ‚Ä¢ Adopts AI\'s systematic approach to citation analysis\n\n3. Mutual Improvement:\n   ‚Ä¢ AI develops better legal reasoning (strategy accuracy: 65% ‚Üí 78%)\n   ‚Ä¢ Lawyer increases research efficiency (time per case: 4h ‚Üí 2.5h)\n   ‚Ä¢ Together they discover novel legal arguments\n\nWeek 12 Results:\n‚Ä¢ Case success rate improved 23%\n‚Ä¢ Research time reduced 40%\n‚Ä¢ Both human and AI capabilities enhanced\n‚Ä¢ New hybrid legal strategies developed\n\nKey Success Factors:\n‚Ä¢ Regular feedback exchange\n‚Ä¢ Shared performance metrics\n‚Ä¢ Complementary strength recognition\n‚Ä¢ Trust building over time'
  },
  {
    id: 'escalation-procedures',
    name: 'Escalation Procedures',
    abbr: 'EP',
    icon: 'üö®',
    color: 'from-orange-500 to-red-600',
    category: 'human-ai-collaboration',
    description: 'Systematic protocols for escalating AI decisions to appropriate human experts when confidence is low or stakes are high',
    features: [
      'Confidence-based escalation triggers',
      'Role-based expert routing',
      'Priority level assignment',
      'Escalation path optimization',
      'Response time guarantees',
      'Fallback mechanisms'
    ],
    useCases: ['customer-support', 'medical-triage', 'fraud-detection', 'content-moderation', 'crisis-management'],
    complexity: 'medium',
    example: 'Customer Support Escalation:\n\nCustomer Query: "My payment was charged twice and I need a refund immediately for rent money"\n\nEscalation Analysis:\n‚Ä¢ Query complexity: High (financial dispute)\n‚Ä¢ Emotional urgency: High (rent payment)\n‚Ä¢ AI confidence: Low (65% - ambiguous transaction details)\n‚Ä¢ Customer tier: Premium (5+ year customer)\n\nEscalation Decision Tree:\n\n1. Trigger Assessment:\n   ‚Ä¢ Low AI confidence (< 70%): ‚úì Escalate\n   ‚Ä¢ High emotional distress: ‚úì Escalate\n   ‚Ä¢ Financial impact > $200: ‚úì Escalate\n   ‚Ä¢ Premium customer: ‚úì Priority escalation\n\n2. Expert Routing:\n   ‚Ä¢ Issue type: Financial dispute ‚Üí Billing specialist\n   ‚Ä¢ Customer tier: Premium ‚Üí Senior agent\n   ‚Ä¢ Urgency: High ‚Üí Within 15 minutes\n   ‚Ä¢ Complexity: High ‚Üí Team lead backup\n\n3. Escalation Execution:\n   ‚Ä¢ Route to: Sarah (Senior Billing Specialist)\n   ‚Ä¢ Priority: High (15-minute SLA)\n   ‚Ä¢ Context package: Customer history, transaction logs, AI analysis\n   ‚Ä¢ Backup: Team Lead Mike (if Sarah unavailable)\n\n4. Resolution:\n   ‚Ä¢ Human expert resolves in 12 minutes\n   ‚Ä¢ Duplicate charge confirmed and refunded\n   ‚Ä¢ Customer satisfaction: 9/10\n   ‚Ä¢ AI learns from expert\'s decision process\n\nEscalation Metrics:\n‚Ä¢ 94% on-time expert engagement\n‚Ä¢ 87% first-contact resolution after escalation\n‚Ä¢ 4.2/5 average customer satisfaction\n‚Ä¢ AI confidence improves by learning from escalations\n\nBenefits:\n‚Ä¢ Ensures complex issues get expert attention\n‚Ä¢ Maintains high customer satisfaction\n‚Ä¢ Protects company from high-risk decisions\n‚Ä¢ Continuously improves AI through expert feedback'
  },
  {
    id: 'feedback-loops',
    name: 'Feedback Loops',
    abbr: 'FL',
    icon: 'üîÑ',
    color: 'from-purple-500 to-indigo-600',
    category: 'human-ai-collaboration',
    description: 'Systematic mechanisms for collecting, processing, and incorporating human feedback to continuously improve AI performance',
    features: [
      'Multi-channel feedback collection',
      'Real-time learning integration',
      'Feedback quality assessment',
      'Automated model updates',
      'Performance impact tracking',
      'Bias detection through feedback'
    ],
    useCases: ['personalization-systems', 'content-recommendation', 'search-optimization', 'predictive-models', 'user-interfaces'],
    complexity: 'high',
    example: 'E-commerce Recommendation System:\n\nContinuous Improvement Through Human Feedback:\n\n1. Feedback Collection:\n   ‚Ä¢ Explicit feedback: Star ratings, thumbs up/down\n   ‚Ä¢ Implicit feedback: Click-through rates, purchase behavior\n   ‚Ä¢ Contextual feedback: "Not interested in this category"\n   ‚Ä¢ Temporal feedback: Seasonal preference changes\n\n2. Feedback Processing:\n   ‚Ä¢ Week 1: 10,000 user interactions collected\n   ‚Ä¢ Positive signals: 6,200 (62%)\n   ‚Ä¢ Negative signals: 2,300 (23%)\n   ‚Ä¢ Neutral/ignored: 1,500 (15%)\n   ‚Ä¢ Quality score: High (low spam/fake feedback)\n\n3. Learning Integration:\n   ‚Ä¢ Real-time updates: Immediate personalization adjustments\n   ‚Ä¢ Batch learning: Weekly model retraining\n   ‚Ä¢ A/B testing: 10% traffic for new model validation\n   ‚Ä¢ Bias monitoring: Demographic fairness checks\n\n4. Performance Impact:\n   ‚Ä¢ Baseline metrics (Month 1):\n     - Click-through rate: 3.2%\n     - Conversion rate: 1.8%\n     - User satisfaction: 6.7/10\n   \n   ‚Ä¢ After feedback integration (Month 3):\n     - Click-through rate: 4.1% (+28%)\n     - Conversion rate: 2.4% (+33%)\n     - User satisfaction: 7.9/10 (+18%)\n\n5. Continuous Monitoring:\n   ‚Ä¢ Daily feedback volume tracking\n   ‚Ä¢ Weekly performance metric reviews\n   ‚Ä¢ Monthly bias and fairness audits\n   ‚Ä¢ Quarterly user satisfaction surveys\n\nFeedback Loop Features:\n‚Ä¢ Multi-granular: Product, category, and system-level feedback\n‚Ä¢ Adaptive: Learning rates adjust based on feedback confidence\n‚Ä¢ Transparent: Users see how their feedback improves recommendations\n‚Ä¢ Ethical: Privacy-preserving feedback processing\n\nResult: Self-improving recommendation system that gets better with use, achieving 33% higher conversion rates through systematic human-AI collaboration'
  }
]; 