import { Technique } from './types';

export const planningExecutionTechniques: Technique[] = [
  {
    id: 'meta-reasoning',
    name: 'Meta-Reasoning',
    abbr: 'MR',
    icon: 'üß†',
    color: 'from-purple-600 to-pink-700',
    category: 'planning-execution',
    description: 'Higher-order reasoning about reasoning processes, including strategy selection and monitoring',
    features: [
      'Reasoning strategy selection',
      'Multi-level reasoning coordination',
      'Strategy performance monitoring',
      'Dynamic strategy switching',
      'Cross-domain strategy transfer',
      'Meta-cognitive monitoring'
    ],
    useCases: ['complex-problem-solving', 'multi-domain-reasoning', 'adaptive-intelligence'],
    complexity: 'high',
    example: 'Multi-Domain Problem: "Design a sustainable smart city"\n\nMeta-Reasoning Process:\n\n1. Problem Analysis (Meta-Level):\n   ‚Ä¢ Identifies sub-domains: Urban planning, Energy, Transport, Economics\n   ‚Ä¢ Selects reasoning strategies per domain:\n     - Urban planning: Hierarchical task networks\n     - Energy: Constraint satisfaction\n     - Transport: Graph optimization\n     - Economics: Probabilistic modeling\n\n2. Strategy Coordination:\n   ‚Ä¢ Parallel reasoning in each domain\n   ‚Ä¢ Cross-domain constraint sharing\n   ‚Ä¢ Conflict resolution between domains\n   ‚Ä¢ Resource allocation based on complexity\n\n3. Dynamic Adaptation:\n   ‚Ä¢ Energy analysis shows renewable constraints\n   ‚Ä¢ Meta-reasoner switches transport strategy to electric-focused\n   ‚Ä¢ Updates economic projections based on energy costs\n   ‚Ä¢ Monitors progress and adjusts strategies\n\n4. Meta-Cognitive Monitoring:\n   ‚Ä¢ "Am I using the right reasoning approach?"\n   ‚Ä¢ "Is progress sufficient for the time remaining?"\n   ‚Ä¢ "Should I try a different strategy?"\n\nMeta-Reasoning Benefits:\n‚Ä¢ Optimal strategy selection per problem type\n‚Ä¢ Dynamic adaptation based on progress\n‚Ä¢ Cross-domain knowledge transfer\n‚Ä¢ Self-awareness of reasoning processes',
    references: [
      'Establishing Meta-Decision-Making for AI: An Ontology of Relevance, Representation and Reasoning (ArXiv 2022)',
      'A meta-cognitive architecture for planning in uncertain environments (ScienceDirect 2013)',
      'Meta-Reasoning in Agents - Evidence-Based Advances in Reflective AI Systems (Computer Society)'
    ]
  },
  {
    id: 'hierarchical-task-network-planning',
    name: 'Hierarchical Task Network (HTN) Planning',
    abbr: 'HTN',
    icon: 'üèóÔ∏è',
    color: 'from-blue-600 to-purple-600',
    category: 'planning-execution',
    description: 'Automated planning approach that decomposes complex tasks into hierarchically structured networks of simpler tasks using domain knowledge',
    features: [
      'Hierarchical task decomposition',
      'Domain knowledge integration',
      'Multi-level task abstraction',
      'Dependency constraint management',
      'Primitive and compound task handling',
      'Method-based task refinement'
    ],
    useCases: ['autonomous-agents', 'multi-agent-systems', 'complex-workflow-automation', 'robotics-planning'],
    complexity: 'high',
    example: 'HTN Planning for Autonomous Research Agent:\n\nTop-Level Task: "Conduct Market Analysis"\n\nHTN Decomposition:\n‚îú‚îÄ Method 1: Comprehensive Analysis\n‚îÇ  ‚îú‚îÄ Task: Gather Data Sources\n‚îÇ  ‚îÇ  ‚îú‚îÄ Primitive: Search Academic Papers\n‚îÇ  ‚îÇ  ‚îú‚îÄ Primitive: Query Market Databases\n‚îÇ  ‚îÇ  ‚îî‚îÄ Primitive: Scrape Industry Reports\n‚îÇ  ‚îú‚îÄ Task: Process Information\n‚îÇ  ‚îÇ  ‚îú‚îÄ Compound: Statistical Analysis\n‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ Primitive: Calculate Trends\n‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Primitive: Identify Correlations\n‚îÇ  ‚îÇ  ‚îî‚îÄ Compound: Competitive Analysis\n‚îÇ  ‚îî‚îÄ Task: Generate Report\n‚îÇ     ‚îú‚îÄ Primitive: Structure Findings\n‚îÇ     ‚îî‚îÄ Primitive: Create Visualizations\n\nConstraints:\n‚Ä¢ Data gathering must complete before processing\n‚Ä¢ Statistical analysis precedes competitive analysis\n‚Ä¢ All analysis must finish before report generation\n\nHTN Advantages:\n‚Ä¢ Domain expertise encoded in methods\n‚Ä¢ Efficient search through task hierarchy\n‚Ä¢ Reusable task decomposition patterns\n‚Ä¢ Human-interpretable plan structure',
    references: [
      'An Overview of Hierarchical Task Network Planning (ArXiv 2014) - https://arxiv.org/abs/1403.7426',
      'HTN planning: Overview, comparison, and beyond (ScienceDirect 2015)',
      'Hierarchical Task Network Planning for Facilitating Cooperative Multi-Agent Reinforcement Learning (ArXiv 2023)'
    ]
  },
  {
    id: 'task-management-orchestration',
    name: 'Task Management & Orchestration',
    abbr: 'TMO',
    icon: '‚úÖ',
    color: 'from-green-600 to-blue-600',
    category: 'planning-execution',
    description: 'Systematic task decomposition, progress tracking, and adaptive workflow management for complex multi-step processes',
    features: [
      'Dynamic task decomposition',
      'Progress state tracking',
      'Dependency management',
      'Priority orchestration',
      'Real-time adaptation',
      'Completion validation',
      'Bottleneck detection',
      'Parallel execution coordination'
    ],
    useCases: ['project-management', 'workflow-orchestration', 'cognitive-load-management', 'progress-tracking', 'collaborative-coordination', 'quality-assurance'],
    complexity: 'medium',
    example: 'AI Model Development Project:\n\n**Task Registry Initialization:**\n```\nProject: "Customer Sentiment Model"\nTasks: [\n  {id: "data-collection", status: "completed", priority: "high"},\n  {id: "data-cleaning", status: "in_progress", depends_on: ["data-collection"]},\n  {id: "feature-engineering", status: "pending", depends_on: ["data-cleaning"]},\n  {id: "model-training", status: "pending", depends_on: ["feature-engineering"]},\n  {id: "validation", status: "pending", depends_on: ["model-training"]},\n  {id: "deployment", status: "pending", depends_on: ["validation"]}\n]\n```\n\n**Orchestration Flow:**\n1. **Dependency Resolution**: Automatically unblocks "data-cleaning" when "data-collection" completes\n2. **Progress Tracking**: Real-time visibility: 1/6 completed, 1/6 in_progress, 4/6 pending\n3. **Adaptive Prioritization**: Urgent deployment deadline ‚Üí increases priority of dependent tasks\n4. **Parallel Execution**: "documentation" and "testing" tasks run parallel to main pipeline\n5. **Bottleneck Detection**: "data-cleaning" taking longer than expected ‚Üí alerts and resource reallocation\n\n**Benefits:**\n‚Ä¢ Clear progress visibility for stakeholders\n‚Ä¢ Automatic dependency management prevents errors\n‚Ä¢ Adaptive scheduling responds to changing requirements\n‚Ä¢ Reduces cognitive load through systematic organization'
  },
  {
    id: 'goal-decomposition',
    name: 'Intelligent Goal Decomposition',
    abbr: 'IGD',
    icon: 'üéØ',
    color: 'from-orange-500 to-yellow-600',
    category: 'planning-execution',
    description: 'Systematic breakdown of complex objectives into achievable, measurable sub-goals with clear success criteria',
    features: [
      'SMART goal creation',
      'Dependency analysis',
      'Resource requirement estimation',
      'Risk assessment',
      'Success metrics definition',
      'Milestone identification'
    ],
    useCases: ['project-planning', 'personal-development', 'business-strategy', 'learning-objectives'],
    complexity: 'medium',
    example: 'AI Model Performance Improvement Goal:\n\nOriginal Goal: "Improve AI model performance"\n‚Üí Problem: Vague, unmeasurable, no timeline\n\nIntelligent Decomposition:\n\nLevel 1 - Strategic Objective:\n"Increase model accuracy from 87% to 95% within 3 months while maintaining <200ms latency"\n\nLevel 2 - Tactical Sub-Goals:\n1. Data Quality Improvement (Month 1)\n   ‚Ä¢ Clean existing dataset\n   ‚Ä¢ Add 10,000 high-quality samples\n   ‚Ä¢ Reduce data noise by 50%\n   ‚Ä¢ Success: Dataset quality score >90%\n\n2. Model Architecture Optimization (Month 2)\n   ‚Ä¢ Experiment with 5 architecture variants\n   ‚Ä¢ Implement ensemble methods\n   ‚Ä¢ Optimize hyperparameters\n   ‚Ä¢ Success: >92% accuracy on validation set\n\n3. Training Process Enhancement (Month 2-3)\n   ‚Ä¢ Implement advanced training techniques\n   ‚Ä¢ Add regularization methods\n   ‚Ä¢ Optimize training pipeline\n   ‚Ä¢ Success: Reduce overfitting by 30%\n\n4. Performance Validation (Month 3)\n   ‚Ä¢ Comprehensive testing on unseen data\n   ‚Ä¢ Latency benchmarking\n   ‚Ä¢ A/B testing in production\n   ‚Ä¢ Success: Meet all performance criteria\n\nLevel 3 - Operational Tasks:\nData Quality Improvement:\n‚Ä¢ Identify data quality issues (2 days)\n‚Ä¢ Implement automated cleaning pipeline (5 days)\n‚Ä¢ Source additional training data (7 days)\n‚Ä¢ Validate data quality improvements (1 day)\n\nResource Requirements:\n‚Ä¢ Human resources: 2 ML engineers, 1 data scientist\n‚Ä¢ Computational: 4 GPU-hours/day for training\n‚Ä¢ Data storage: 500GB additional capacity\n‚Ä¢ Budget: $15,000 for data acquisition\n\nRisk Assessment:\n‚Ä¢ High risk: New data may not improve performance\n‚Ä¢ Medium risk: Architecture changes affect latency\n‚Ä¢ Low risk: Training time exceeds estimates\n‚Ä¢ Mitigation: Parallel experiments, rollback plans\n\nProgress Tracking:\nWeek 4 Results:\n‚Ä¢ Data quality: 92% complete (ahead of schedule)\n‚Ä¢ Model accuracy: 89.5% (good progress)\n‚Ä¢ Latency: 185ms (within limits)\n‚Ä¢ Risk status: All risks under control\n\nAdaptive Refinement:\n‚Ä¢ Discovery: Ensemble methods show promise\n‚Ä¢ Adjustment: Allocate more resources to ensembles\n‚Ä¢ Timeline: Maintain 3-month deadline\n‚Ä¢ Quality gate: 93% accuracy by end of month 2\n\nResults:\n‚Ä¢ Final accuracy: 94.8% (close to target)\n‚Ä¢ Latency: 178ms (exceeded target)\n‚Ä¢ Timeline: Delivered 1 week early\n‚Ä¢ Team satisfaction: Clear goals improved focus'
  }
];