import { Technique } from './types';

export const uiUxPatterns: Technique[] = [
  // === Human-AI Collaboration Patterns ===
  {
    id: 'human-in-the-loop',
    name: 'Human-in-the-Loop',
    abbr: 'HITL',
    icon: 'üë§',
    color: 'from-blue-500 to-indigo-600',
    category: 'ui-ux-patterns',
    description: 'Strategic integration of human judgment at critical decision points in AI workflows',
    features: [
      'Strategic human intervention points',
      'Confidence-based escalation',
      'Human expertise integration',
      'Quality assurance checkpoints',
      'Feedback loop optimization',
      'Domain expert validation'
    ],
    useCases: ['medical-diagnosis', 'legal-analysis', 'financial-decisions', 'content-moderation', 'safety-critical-systems'],
    complexity: 'medium',
    example: 'Medical Imaging Analysis:\n\n1. AI Analysis:\n   ‚Ä¢ Scans chest X-ray\n   ‚Ä¢ Detects potential abnormality (78% confidence)\n   ‚Ä¢ Flags for human review (threshold: 80%)\n\n2. Human Intervention:\n   ‚Ä¢ Radiologist reviews flagged case\n   ‚Ä¢ Confirms suspicious mass in upper left lobe\n   ‚Ä¢ Adds contextual notes: "Consider CT follow-up"\n\n3. Collaborative Decision:\n   ‚Ä¢ AI + Human consensus: "Abnormal finding requiring further investigation"\n   ‚Ä¢ Confidence increased to 95%\n   ‚Ä¢ Automatic scheduling of follow-up CT\n\nBenefits:\n‚Ä¢ AI handles routine cases (85% of volume)\n‚Ä¢ Human expertise for complex/uncertain cases\n‚Ä¢ Continuous learning from human feedback\n‚Ä¢ Maintains final human accountability'
  },
  {
    id: 'human-on-the-loop',
    name: 'Human On the Loop',
    abbr: 'HOTL',
    icon: 'üëÅÔ∏è',
    color: 'from-cyan-500 to-blue-600',
    category: 'ui-ux-patterns',
    description: 'Human supervisory oversight of autonomous AI systems with ability to monitor, intervene, or take control when necessary',
    features: [
      'Continuous monitoring and observation',
      'Exception-based intervention',
      'Override and takeover capabilities',
      'Performance monitoring dashboards',
      'Automated alert systems',
      'Supervisory control interfaces'
    ],
    useCases: ['autonomous-vehicles', 'trading-systems', 'manufacturing-automation', 'air-traffic-control', 'process-monitoring'],
    complexity: 'high',
    example: 'Autonomous Trading System:\n\nNormal Operation (Human On the Loop):\n\n1. AI Trading Activity:\n   ‚Ä¢ Executes 1,200 trades per hour automatically\n   ‚Ä¢ Follows programmed strategies and risk parameters\n   ‚Ä¢ Maintains portfolio within defined risk limits\n   ‚Ä¢ Performance: +2.3% daily return\n\n2. Human Monitoring:\n   ‚Ä¢ Trader monitors via real-time dashboard\n   ‚Ä¢ Watches key metrics: P&L, volume, risk exposure\n   ‚Ä¢ Reviews automated alerts and warnings\n   ‚Ä¢ No intervention needed - system operating normally\n\n3. Exception Scenario:\n   ‚Ä¢ Market volatility spikes unexpectedly\n   ‚Ä¢ AI system detects unusual market conditions\n   ‚Ä¢ Automated alert: "High volatility detected - review recommended"\n   ‚Ä¢ Risk exposure approaching upper limit\n\n4. Human Intervention:\n   ‚Ä¢ Trader reviews situation in 30 seconds\n   ‚Ä¢ Decides market conditions are too volatile\n   ‚Ä¢ Takes manual control: "Override - reduce position size by 50%"\n   ‚Ä¢ AI continues with new human-set parameters\n\n5. Return to Autonomy:\n   ‚Ä¢ Market conditions stabilize after 2 hours\n   ‚Ä¢ Trader approves return to full autonomous operation\n   ‚Ä¢ AI resumes normal trading with lessons learned\n\nMonitoring Features:\n‚Ä¢ Real-time performance dashboard\n‚Ä¢ Configurable alert thresholds\n‚Ä¢ One-click intervention capabilities\n‚Ä¢ Audit trail of all human interventions\n‚Ä¢ Automated reporting and analysis\n\nBenefits:\n‚Ä¢ Enables high-speed autonomous operation\n‚Ä¢ Human expertise available when needed\n‚Ä¢ Reduces human workload (95% autonomous time)\n‚Ä¢ Maintains ultimate human control and accountability\n‚Ä¢ Allows humans to focus on strategic decisions'
  },

  // === UI/UX Interface Patterns ===
  // Foundational Human-Agent Interaction Patterns (8 techniques)
  {
    id: 'progressive-disclosure-patterns',
    name: 'Progressive Disclosure UI Patterns',
    abbr: 'PDP',
    icon: 'üìã',
    color: 'from-slate-500 to-gray-600',
    category: 'ui-ux-patterns',
    description: 'Interface patterns for gradually revealing agent capabilities, reasoning, and complex information to prevent cognitive overload',
    features: [
      'Expandable reasoning trees with step-by-step disclosure',
      'Collapsible explanation panels with detail levels',
      'Staged capability introduction during onboarding',
      'Context-sensitive information revelation'
    ],
    useCases: ['complex-reasoning', 'user-education', 'capability-introduction', 'cognitive-load-management'],
    complexity: 'high',
    example: 'Agent Reasoning Progressive Disclosure:\n\n1. Expandable Decision Trees:\n   ‚Ä¢ Initial summary with key decision factors\n   ‚Ä¢ Click-to-expand reasoning branches\n   ‚Ä¢ Progressive detail levels (summary ‚Üí detailed ‚Üí technical)\n   ‚Ä¢ Visual hierarchy with indentation and icons\n\n2. Collapsible Panels:\n   ‚Ä¢ "Show reasoning" toggle for explanations\n   ‚Ä¢ Accordion-style information sections\n   ‚Ä¢ Nested disclosure for complex processes\n   ‚Ä¢ Breadcrumb navigation for deep dives\n\n3. Staged Capability Introduction:\n   ‚Ä¢ Basic features first, advanced later\n   ‚Ä¢ Contextual feature discovery prompts\n   ‚Ä¢ Just-in-time capability reveals\n   ‚Ä¢ User-paced exploration controls\n\nResult: 67% reduction in cognitive overload, 45% better comprehension'
  },
  {
    id: 'confidence-visualization-patterns',
    name: 'Confidence Visualization UI Patterns',
    abbr: 'CVP',
    icon: 'üìä',
    color: 'from-amber-500 to-orange-600',
    category: 'ui-ux-patterns',
    description: 'Visual interface elements for displaying AI confidence levels, uncertainty, and prediction reliability in user-friendly formats',
    features: [
      'Confidence meters with color-coded reliability indicators',
      'Uncertainty ranges and probabilistic displays',
      'N-best classification with alternative suggestions',
      'Visual risk assessment and reliability scores'
    ],
    useCases: ['decision-support', 'risk-assessment', 'prediction-reliability', 'uncertainty-communication'],
    complexity: 'high',
    example: 'AI Confidence Display System:\n\n1. Visual Confidence Indicators:\n   ‚Ä¢ Progress bars: 0-100% confidence with color coding\n   ‚Ä¢ Gauge charts: speedometer-style confidence meters\n   ‚Ä¢ Star ratings: simplified 1-5 reliability scales\n   ‚Ä¢ Badge system: "High/Medium/Low Confidence" labels\n\n2. Uncertainty Communication:\n   ‚Ä¢ Range displays: "75-85% likely" with error bars\n   ‚Ä¢ Probability distributions: bell curves for outcomes\n   ‚Ä¢ Multiple scenarios: "Most likely" vs "Alternative" options\n   ‚Ä¢ Risk indicators: warning icons for low confidence\n\n3. Contextual Implementation:\n   ‚Ä¢ Inline confidence for individual recommendations\n   ‚Ä¢ Modal overlays for detailed uncertainty analysis\n   ‚Ä¢ Tooltip explanations for confidence factors\n   ‚Ä¢ Dashboard summaries for overall system reliability\n\nTrust Calibration: 82% improvement in appropriate reliance on AI'
  },
  {
    id: 'mixed-initiative-interface-patterns',
    name: 'Mixed-Initiative Interface Patterns',
    abbr: 'MIP',
    icon: 'üîÑ',
    color: 'from-emerald-500 to-teal-600',
    category: 'ui-ux-patterns',
    description: 'UI patterns for seamless control switching between human and AI agents, enabling collaborative initiative-taking',
    features: [
      'Control handoff buttons with clear state indicators',
      'Initiative indicators showing who is currently leading',
      'Seamless transition interfaces for control switching',
      'Collaborative suggestion and override mechanisms'
    ],
    useCases: ['collaborative-work', 'human-ai-partnership', 'control-sharing', 'initiative-management'],
    complexity: 'high',
    example: 'Human-AI Initiative Management:\n\n1. Control State Indicators:\n   ‚Ä¢ "Human Leading" vs "AI Leading" status badges\n   ‚Ä¢ Color-coded borders around active control areas\n   ‚Ä¢ Initiative history timeline showing handoffs\n   ‚Ä¢ Clear ownership indicators for current actions\n\n2. Handoff Mechanisms:\n   ‚Ä¢ "Take Control" button for human override\n   ‚Ä¢ "Let AI Handle" delegation options\n   ‚Ä¢ Temporary control with automatic return timers\n   ‚Ä¢ Collaborative mode with shared initiative\n\n3. Transition UX:\n   ‚Ä¢ Smooth animations for control transfers\n   ‚Ä¢ Context preservation during handoffs\n   ‚Ä¢ Confirmation dialogs for critical transitions\n   ‚Ä¢ Undo/redo for initiative decisions\n\nCollaboration Efficiency: 73% faster task completion in mixed-initiative mode'
  },
  {
    id: 'agent-status-activity-patterns',
    name: 'Agent Status & Activity UI Patterns',
    abbr: 'ASP',
    icon: '‚ö°',
    color: 'from-violet-500 to-purple-600',
    category: 'ui-ux-patterns',
    description: 'Interface elements showing real-time agent activities, thinking states, and operational status for user awareness',
    features: [
      'Real-time activity indicators and progress visualizations',
      'Thinking state animations and processing displays',
      'Agent status badges with operational health metrics',
      'Background task indicators and queue management'
    ],
    useCases: ['status-awareness', 'activity-monitoring', 'progress-tracking', 'system-transparency'],
    complexity: 'medium',
    example: 'Agent Activity Visualization:\n\n1. Thinking State Indicators:\n   ‚Ä¢ Animated dots for "agent is thinking"\n   ‚Ä¢ Pulsing icons during processing states\n   ‚Ä¢ Progress spinners with time estimates\n   ‚Ä¢ Typing indicators adapted for AI responses\n\n2. Activity Status Display:\n   ‚Ä¢ "Analyzing document..." with progress percentage\n   ‚Ä¢ "Searching databases..." with source indicators\n   ‚Ä¢ "Generating response..." with completion estimates\n   ‚Ä¢ "Waiting for user input..." idle state clarity\n\n3. Background Process Management:\n   ‚Ä¢ Minimized activity panels for ongoing tasks\n   ‚Ä¢ Queue indicators showing pending operations\n   ‚Ä¢ Priority badges for urgent vs routine tasks\n   ‚Ä¢ Completion notifications with summary results\n\nUser Awareness: 91% improvement in understanding agent operations'
  },
  {
    id: 'conversational-interface-patterns',
    name: 'Conversational Interface Patterns',
    abbr: 'CIP',
    icon: 'üí¨',
    color: 'from-blue-500 to-indigo-600',
    category: 'ui-ux-patterns',
    description: 'Advanced conversational UI/UX patterns that move beyond traditional chatbots to agent-driven, multimodal experiences',
    features: [
      'Agent-driven proactive interactions beyond reactive chat',
      'Multimodal conversation integration (voice, text, visual)',
      'Context-aware communication modality selection',
      'Natural conversation flow with seamless interruptions'
    ],
    useCases: ['intelligent-assistants', 'customer-service-agents', 'educational-tutors', 'collaborative-ai'],
    complexity: 'high',
    example: 'Advanced Agent Conversation Design:\n\n1. Agent-Driven Interaction:\n   ‚Ä¢ Proactive need anticipation based on context\n   ‚Ä¢ Dynamic response adaptation to user situation\n   ‚Ä¢ Real-time data integration for relevance\n   ‚Ä¢ Initiative-taking for helpful actions\n\n2. Multimodal Integration:\n   ‚Ä¢ Automatic modality selection (text/voice/visual)\n   ‚Ä¢ Seamless transitions between communication modes\n   ‚Ä¢ Context-appropriate interaction patterns\n   ‚Ä¢ Natural conversation flow preservation\n\n3. UX Implementation:\n   ‚Ä¢ Progressive disclosure for complex information\n   ‚Ä¢ Visual indicators for agent reasoning process\n   ‚Ä¢ User control over conversation style and depth\n\nResult: 300% improvement in user satisfaction vs traditional chatbots'
  },
  {
    id: 'agent-collaboration-ux',
    name: 'Agent Collaboration UX',
    abbr: 'ACX',
    icon: 'ü§ù',
    color: 'from-indigo-500 to-purple-600',
    category: 'ui-ux-patterns',
    description: 'User experience patterns for multi-agent coordination, handoffs, and collaborative workflows with transparent orchestration',
    features: [
      'Seamless agent handoff interfaces with context preservation',
      'Multi-agent coordination dashboards and status visualization',
      'Specialization indicators showing agent expertise areas',
      'Collaborative workflow progress tracking and transparency'
    ],
    useCases: ['enterprise-automation', 'complex-problem-solving', 'multi-step-workflows', 'specialized-teams'],
    complexity: 'high',
    example: 'Enterprise Multi-Agent Collaboration UX:\n\n1. Agent Handoff Design:\n   ‚Ä¢ Visual handoff indicators with smooth transitions\n   ‚Ä¢ Context summary generation for continuity\n   ‚Ä¢ User consent options for agent changes\n   ‚Ä¢ Reason communication for handoff decisions\n\n2. Coordination Dashboard:\n   ‚Ä¢ Real-time agent status visualization\n   ‚Ä¢ Task distribution and progress tracking\n   ‚Ä¢ Specialization badges and capability indicators\n   ‚Ä¢ Network graph of inter-agent communication\n\n3. User Control:\n   ‚Ä¢ Intervention points for human oversight\n   ‚Ä¢ Agent preference settings and customization\n   ‚Ä¢ Quality feedback mechanisms for improvements\n\nResult: 60% QA time savings, weeks-to-days project timelines'
  },
  {
    id: 'trust-transparency-patterns',
    name: 'Trust and Transparency Patterns',
    abbr: 'TTP',
    icon: 'üîç',
    color: 'from-purple-500 to-pink-600',
    category: 'ui-ux-patterns',
    description: 'Design patterns for building user trust through explainable AI interfaces, decision transparency, and source attribution',
    features: [
      'Explainable AI interfaces with progressive disclosure',
      'Decision visualization and reasoning transparency',
      'Source attribution and citation systems',
      'Confidence indicators and uncertainty communication'
    ],
    useCases: ['high-stakes-decisions', 'enterprise-ai', 'regulated-industries', 'professional-tools'],
    complexity: 'high',
    example: 'Salesforce AI Trust Framework Implementation:\n\n1. Mindful Friction:\n   ‚Ä¢ Intentional pauses for high-stakes decisions\n   ‚Ä¢ Confirmation dialogs with clear consequences\n   ‚Ä¢ User control over automation levels\n\n2. Transparency Indicators:\n   ‚Ä¢ Einstein "sparkles" icon for AI-generated content\n   ‚Ä¢ Clear input data and algorithm disclosure\n   ‚Ä¢ Expandable explanation panels on demand\n   ‚Ä¢ Three-level interpretability (how, why, trust)\n\n3. Source Attribution:\n   ‚Ä¢ Clear citation systems with clickable sources\n   ‚Ä¢ Information provenance tracking\n   ‚Ä¢ Confidence metrics with uncertainty ranges\n   ‚Ä¢ Bias detection alerts and safeguards\n\nTrust Score: 95% user confidence in AI recommendations'
  },
  {
    id: 'adaptive-interface-patterns',
    name: 'Adaptive Interface Patterns',
    abbr: 'AIP',
    icon: 'üéØ',
    color: 'from-pink-500 to-red-600',
    category: 'ui-ux-patterns',
    description: 'Dynamic UI/UX adaptation and creation patterns that personalize agent interfaces based on user context, behavior, and preferences',
    features: [
      'Real-time interface adaptation based on user context',
      'Personalization engines with behavioral learning',
      'Context-aware UI element adjustment and customization',
      'Adaptive communication style and interaction patterns'
    ],
    useCases: ['personal-assistants', 'adaptive-learning', 'accessibility', 'user-personalization'],
    complexity: 'high',
    example: 'SELF-RAG Adaptive Interface System:\n\n1. Adaptation Engine:\n   ‚Ä¢ Context state vector generation from user behavior\n   ‚Ä¢ Real-time analysis of interaction patterns\n   ‚Ä¢ Preference learning from implicit feedback\n\n2. Interface Generator:\n   ‚Ä¢ Dynamic layout adjustments for optimal usability\n   ‚Ä¢ Content presentation style adaptation\n   ‚Ä¢ Communication tone and complexity adjustment\n   ‚Ä¢ Modality selection based on context\n\n3. User Control:\n   ‚Ä¢ Adaptation preference settings and transparency\n   ‚Ä¢ Override options for automatic adjustments\n   ‚Ä¢ Privacy controls for behavioral data collection\n\nAdaptation Accuracy: 87% correct interface adjustments'
  },

  // Real-Time Control and Monitoring Patterns (4 techniques)
  {
    id: 'context-window-management-patterns',
    name: 'Context Window Management UI',
    abbr: 'CWM',
    icon: 'ü™ü',
    color: 'from-rose-500 to-pink-600',
    category: 'ui-ux-patterns',
    description: 'Visual patterns for managing LLM context limits, token usage, and context window optimization in agent interfaces',
    features: [
      'Context usage meters with visual token consumption tracking',
      'Priority indicators for context retention decisions',
      'Context compression controls with user preferences',
      'Memory summarization interfaces and context pruning'
    ],
    useCases: ['llm-optimization', 'token-management', 'context-efficiency', 'memory-management'],
    complexity: 'medium',
    example: 'LLM Context Window Management:\n\n1. Context Usage Visualization:\n   ‚Ä¢ Progress bar showing token usage (7,500/8,000 tokens)\n   ‚Ä¢ Color coding: green ‚Üí yellow ‚Üí red as limit approaches\n   ‚Ä¢ Real-time updates as conversation progresses\n   ‚Ä¢ Estimated remaining conversation turns\n\n2. Context Priority Controls:\n   ‚Ä¢ "Pin important messages" for context retention\n   ‚Ä¢ Automatic summarization of older conversations\n   ‚Ä¢ Manual context pruning with user selection\n   ‚Ä¢ Smart compression with key information preservation\n\n3. Memory Management Interface:\n   ‚Ä¢ Collapsible conversation history sections\n   ‚Ä¢ Summary previews of compressed content\n   ‚Ä¢ "Restore full context" options for detailed recall\n   ‚Ä¢ Context overlap indicators for continuity\n\nEfficiency: 65% better context utilization, 40% longer conversations'
  },
  {
    id: 'monitoring-control-patterns',
    name: 'Monitoring and Control Patterns',
    abbr: 'MCP',
    icon: 'üéõÔ∏è',
    color: 'from-red-500 to-orange-600',
    category: 'ui-ux-patterns',
    description: 'Mission-control style interfaces for real-time agent oversight, intervention capabilities, and system monitoring',
    features: [
      'Real-time agent status monitoring with exception handling',
      'Mission-control dashboards for complex agent networks',
      'Intervention mechanisms with start/stop/pause controls',
      'Anomaly detection with proactive alert systems'
    ],
    useCases: ['enterprise-monitoring', 'critical-systems', 'agent-orchestration', 'operational-oversight'],
    complexity: 'high',
    example: 'Enterprise Agent Mission Control:\n\n1. Control Systems:\n   ‚Ä¢ Start/stop/pause controls for agent workflows\n   ‚Ä¢ Emergency halt capabilities for all operations\n   ‚Ä¢ Real-time status visibility across agent network\n   ‚Ä¢ Cross-platform control consistency\n\n2. Monitoring Dashboard:\n   ‚Ä¢ Multi-level information hierarchy (summary to detail)\n   ‚Ä¢ Exception-based alerts for anomalies\n   ‚Ä¢ Performance metrics and efficiency tracking\n   ‚Ä¢ Agent coordination visualization\n\n3. Intervention Points:\n   ‚Ä¢ Clear escalation mechanisms for human involvement\n   ‚Ä¢ Automated vs manual decision indicators\n   ‚Ä¢ Quality feedback loops for system improvement\n\nSystem Reliability: 99.8% uptime with proactive monitoring'
  },
  {
    id: 'error-recovery-patterns',
    name: 'Error Handling and Recovery Patterns',
    abbr: 'ERP',
    icon: 'üîß',
    color: 'from-orange-500 to-yellow-600',
    category: 'ui-ux-patterns',
    description: 'Comprehensive error communication and recovery interface patterns for graceful failure handling in agent systems',
    features: [
      'Progressive error disclosure with actionable solutions',
      'Multiple error display modalities (inline, modal, banner)',
      'Automated recovery suggestion and implementation',
      'Context preservation during error recovery processes'
    ],
    useCases: ['production-systems', 'user-support', 'error-prevention', 'system-resilience'],
    complexity: 'medium',
    example: 'Agent Error Handling Framework:\n\n1. Three-Element Error Communication:\n   ‚Ä¢ Problem statement: Clear description of what happened\n   ‚Ä¢ Cause explanation: Understanding of why error occurred\n   ‚Ä¢ Solution suggestion: Actionable steps for resolution\n\n2. Display Method Selection:\n   ‚Ä¢ Inline validation for real-time input errors\n   ‚Ä¢ Tooltips for minor issues with contextual help\n   ‚Ä¢ Modals for critical or irreversible errors\n   ‚Ä¢ Banners for persistent important communications\n\n3. Recovery Systems:\n   ‚Ä¢ Automatic context restoration capabilities\n   ‚Ä¢ Progressive disclosure of technical details\n   ‚Ä¢ User-friendly language avoiding jargon\n   ‚Ä¢ Accessibility compliance with visual indicators\n\nRecovery Success: 95% automatic error resolution'
  },
  {
    id: 'onboarding-education-patterns',
    name: 'Onboarding and Education Patterns',
    abbr: 'OEP',
    icon: 'üéì',
    color: 'from-yellow-500 to-green-600',
    category: 'ui-ux-patterns',
    description: 'User education and onboarding patterns for introducing agent capabilities, building appropriate mental models, and fostering trust',
    features: [
      'Progressive disclosure of agent capabilities and limitations',
      'Interactive tutorials for agent interaction patterns',
      'Mental model building through clear capability communication',
      'Trust building through transparency and expectation setting'
    ],
    useCases: ['user-education', 'agent-introduction', 'capability-demonstration', 'trust-building'],
    complexity: 'medium',
    example: 'AI-Powered Agent Onboarding:\n\n1. Progressive Disclosure:\n   ‚Ä¢ Information chunking in manageable steps\n   ‚Ä¢ Guided progression through agent features\n   ‚Ä¢ Contextual assistance based on user progress\n   ‚Ä¢ Cognitive overload prevention strategies\n\n2. Capability Education:\n   ‚Ä¢ Clear communication of agent abilities and limits\n   ‚Ä¢ Example scenarios and practical demonstrations\n   ‚Ä¢ Interaction pattern education and best practices\n   ‚Ä¢ Feedback mechanism training for improvement\n\n3. Trust Building:\n   ‚Ä¢ Transparency about agent decision-making processes\n   ‚Ä¢ Control demonstration and override capabilities\n   ‚Ä¢ Safety mechanism explanation and reassurance\n   ‚Ä¢ Honest limitation communication to prevent disappointment\n\nOnboarding Impact: 50% retention increase, 77% three-day return rate'
  },

  // Security and Privacy UX Patterns (2 techniques)
  {
    id: 'privacy-security-ux',
    name: 'Privacy and Security UX',
    abbr: 'PSX',
    icon: 'üîí',
    color: 'from-green-500 to-teal-600',
    category: 'ui-ux-patterns',
    description: 'Privacy-first design patterns for agent systems with transparent data handling, granular controls, and user empowerment',
    features: [
      'Granular privacy controls with clear data usage explanation',
      'Transparent data collection practices and user rights',
      'Security UX toolkit with usability and protection balance',
      'GDPR/CCPA compliance patterns with user-friendly interfaces'
    ],
    useCases: ['enterprise-compliance', 'personal-data-protection', 'regulated-industries', 'user-empowerment'],
    complexity: 'high',
    example: 'Microsoft Security UX Framework:\n\n1. Privacy Experience (PX) Framework:\n   ‚Ä¢ User-first design with control priority\n   ‚Ä¢ Granular data type selection and purpose permissions\n   ‚Ä¢ Easy data access, correction, and deletion rights\n   ‚Ä¢ Plain language communication avoiding jargon\n\n2. Security Toolkit Components:\n   ‚Ä¢ Usability: familiar language and intuitive interfaces\n   ‚Ä¢ Security: cyber threat protection with risk communication\n   ‚Ä¢ Accessibility: inclusive design for security features\n   ‚Ä¢ Privacy: simple settings with immediate effect\n\n3. Agent-Specific Patterns:\n   ‚Ä¢ HTTPS encryption with strict access controls\n   ‚Ä¢ Essential data collection only policies\n   ‚Ä¢ User control over conversation history\n   ‚Ä¢ Compliance automation with audit trails\n\nCompliance Score: 100% GDPR/CCPA adherence'
  },
  {
    id: 'accessibility-agent-design',
    name: 'Accessibility in Agent Design',
    abbr: 'AAD',
    icon: '‚ôø',
    color: 'from-teal-500 to-blue-600',
    category: 'ui-ux-patterns',
    description: 'Universal design patterns for accessible agent interfaces supporting diverse abilities and assistive technologies',
    features: [
      'Universal agent interface design for diverse abilities',
      'Assistive technology integration and optimization',
      'Multiple communication modalities for accessibility',
      'Cognitive accessibility with simplified interaction patterns'
    ],
    useCases: ['inclusive-design', 'assistive-technology', 'universal-access', 'cognitive-support'],
    complexity: 'high',
    example: 'AI-Mediated Accessibility Framework:\n\n1. Dynamic Accommodation:\n   ‚Ä¢ Real-time adjustment to user needs and preferences\n   ‚Ä¢ Content transformation to user-specific formats\n   ‚Ä¢ AI-powered accessibility enablement layer\n   ‚Ä¢ Personalized adaptation through assistant assistance\n\n2. Communication Accessibility:\n   ‚Ä¢ Multiple modalities: text, voice, and visual options\n   ‚Ä¢ Speed control for agent response adjustment\n   ‚Ä¢ Complexity adjustment with simplified language\n   ‚Ä¢ Predictable behavior patterns for cognitive support\n\n3. Technical Implementation:\n   ‚Ä¢ WCAG compliance with proper heading structure\n   ‚Ä¢ Keyboard interaction management and focus indicators\n   ‚Ä¢ Screen reader optimization with descriptive labels\n   ‚Ä¢ Color-independent information design\n\nAccessibility Impact: 350M+ people with improved AI access'
  },

  // Ambient and Contextual Patterns (2 techniques)
  {
    id: 'ambient-agent-patterns',
    name: 'Ambient Agent Patterns',
    abbr: 'AAP',
    icon: 'üåä',
    color: 'from-emerald-500 to-cyan-600',
    category: 'ui-ux-patterns',
    description: 'Always-present, contextually-aware agent interfaces that operate seamlessly in the background while remaining accessible when needed',
    features: [
      'Contextual awareness with environmental and user state sensing',
      'Proactive assistance without intrusive interruptions',
      'Seamless background operation with selective foreground presence',
      'Anticipatory actions based on learned patterns and preferences'
    ],
    useCases: ['smart-environments', 'personal-assistants', 'iot-integration', 'continuous-monitoring'],
    complexity: 'high',
    example: 'Smart Environment Ambient Agent System:\n\n1. Environmental Integration:\n   ‚Ä¢ IoT sensor data fusion for context awareness\n   ‚Ä¢ Automatic lighting, temperature, and security adjustments\n   ‚Ä¢ Occupancy detection with privacy-preserving inference\n   ‚Ä¢ Energy optimization through behavioral pattern learning\n\n2. Proactive Assistance Patterns:\n   ‚Ä¢ Calendar-aware preparation (meeting room setup, document preparation)\n   ‚Ä¢ Health monitoring with gentle wellness nudges\n   ‚Ä¢ Security alerts with context-appropriate responses\n   ‚Ä¢ Predictive maintenance notifications\n\n3. Interaction Design:\n   ‚Ä¢ Minimal interface footprint with available-when-needed access\n   ‚Ä¢ Voice activation with natural language understanding\n   ‚Ä¢ Gesture recognition for hands-free control\n   ‚Ä¢ Visual ambient displays for status communication\n\nResult: 40% improvement in daily productivity, 60% reduction in manual environment control'
  },
  {
    id: 'chat-interface-patterns',
    name: 'Chat Interface Patterns',
    abbr: 'CIP',
    icon: 'üí≠',
    color: 'from-cyan-500 to-blue-600',
    category: 'ui-ux-patterns',
    description: 'Specialized chat interface patterns optimized for agent interactions, including message threading, context management, and rich content display',
    features: [
      'Threaded conversations with context branching and merging',
      'Rich media integration with documents, images, and interactive elements',
      'Real-time collaboration indicators and typing awareness',
      'Message reactions, annotations, and collaborative editing capabilities'
    ],
    useCases: ['team-collaboration', 'customer-support', 'educational-platforms', 'content-creation'],
    complexity: 'high',
    example: 'Advanced Agent Chat Interface:\n\n1. Message Threading Architecture:\n   ‚Ä¢ Conversation branching for exploring multiple topics\n   ‚Ä¢ Context preservation across thread switches\n   ‚Ä¢ Visual thread indicators and navigation aids\n   ‚Ä¢ Automatic thread summarization and merging\n\n2. Rich Content Integration:\n   ‚Ä¢ Document preview and collaborative editing\n   ‚Ä¢ Code syntax highlighting with execution capabilities\n   ‚Ä¢ Image analysis and annotation tools\n   ‚Ä¢ Interactive forms and data collection widgets\n\n3. Collaboration Features:\n   ‚Ä¢ Real-time presence indicators for human and AI participants\n   ‚Ä¢ Message reactions and emoji responses\n   ‚Ä¢ Voice message integration with transcription\n   ‚Ä¢ Screen sharing and whiteboard collaboration\n\n4. Agent-Specific Enhancements:\n   ‚Ä¢ Thinking indicators showing agent reasoning process\n   ‚Ä¢ Source citation with expandable reference details\n   ‚Ä¢ Confidence metrics and uncertainty communication\n   ‚Ä¢ Suggested follow-up questions and action items\n\nResult: 85% user satisfaction, 50% faster problem resolution'
  },

  // Cross-Platform and Multimodal Patterns (3 techniques)
  {
    id: 'cross-platform-agent-ux',
    name: 'Cross-Platform Agent UX',
    abbr: 'CPX',
    icon: 'üì±',
    color: 'from-blue-500 to-cyan-600',
    category: 'ui-ux-patterns',
    description: 'Consistent agent experience patterns across devices and platforms with seamless synchronization and adaptation',
    features: [
      'Unified agent experience across desktop, mobile, and web',
      'Seamless cross-device synchronization and state management',
      'Platform-optimized adaptation while maintaining consistency',
      'Context-aware feature activation based on device capabilities'
    ],
    useCases: ['multi-device-workflows', 'mobile-optimization', 'platform-consistency', 'device-adaptation'],
    complexity: 'high',
    example: 'Cross-Platform Agent Consistency:\n\n1. Consistency Framework:\n   ‚Ä¢ UI design uniformity: colors, typography, layout\n   ‚Ä¢ Functional consistency: same capabilities across devices\n   ‚Ä¢ Interaction standardization: appropriate gestures per platform\n   ‚Ä¢ Brand coherence: unified expression and voice\n\n2. Multi-Device Integration:\n   ‚Ä¢ Context switching: seamless movement between devices\n   ‚Ä¢ Real-time synchronization: instant cross-device updates\n   ‚Ä¢ State preservation: maintaining progress across platforms\n   ‚Ä¢ Cross-device notifications: appropriate alert distribution\n\n3. AI-Powered Features:\n   ‚Ä¢ Real-time personalization: instant preference adaptation\n   ‚Ä¢ Voice UX sophistication: advanced interaction patterns\n   ‚Ä¢ Gestural interfaces: natural recognition and response\n   ‚Ä¢ Micro-interaction enhancement: AI-powered refinements\n\nUser Satisfaction: 89% consistent experience rating'
  },
  {
    id: 'visual-reasoning-patterns',
    name: 'Visual Reasoning Patterns',
    abbr: 'VRP',
    icon: 'üëÅÔ∏è',
    color: 'from-cyan-500 to-indigo-600',
    category: 'ui-ux-patterns',
    description: 'Visual representation patterns for agent reasoning, decision-making processes, and cognitive transparency',
    features: [
      'Agent reasoning process visualization and decision trees',
      'Step-by-step progress indicators for complex workflows',
      'Confidence metrics and uncertainty visualization',
      'Source highlighting and information provenance display'
    ],
    useCases: ['decision-support', 'transparency', 'education', 'debugging'],
    complexity: 'high',
    example: 'Agent Reasoning Visualization:\n\n1. Decision Transparency Patterns:\n   ‚Ä¢ Step-by-step progress indicators for workflow clarity\n   ‚Ä¢ Expandable explanation panels with progressive disclosure\n   ‚Ä¢ Confidence metrics showing prediction reliability\n   ‚Ä¢ Source highlighting for key data influences\n\n2. Visual Methods:\n   ‚Ä¢ Decision tree visualization for reasoning paths\n   ‚Ä¢ Network graphs for information relationships\n   ‚Ä¢ Timeline representations for process flows\n   ‚Ä¢ Heat maps for attention and importance\n\n3. User Interaction:\n   ‚Ä¢ Drill-down capabilities for detailed explanations\n   ‚Ä¢ Interactive exploration of reasoning paths\n   ‚Ä¢ Comparison views for alternative decisions\n   ‚Ä¢ Export options for documentation and sharing\n\nTrust Building: 78% increase in user confidence with visualizations'
  },
  {
    id: 'multimodal-interaction-patterns',
    name: 'Multimodal Interaction Patterns',
    abbr: 'MMIP',
    icon: 'üé§',
    color: 'from-indigo-500 to-purple-600',
    category: 'ui-ux-patterns',
    description: 'Advanced multimodal agent interaction patterns integrating voice, visual, gesture, and text communication seamlessly',
    features: [
      'Context-aware modality selection and automatic switching',
      'Voice-visual-text integration with natural transitions',
      'Gesture recognition and multimodal input processing',
      'Emotional adaptation and real-time user state assessment'
    ],
    useCases: ['natural-interaction', 'hands-free-operation', 'accessibility', 'contextual-adaptation'],
    complexity: 'high',
    example: 'Advanced Multimodal Agent Interface:\n\n1. Adaptive Modality Selection:\n   ‚Ä¢ Context-aware communication mode selection\n   ‚Ä¢ Environmental factor consideration (noise, privacy)\n   ‚Ä¢ User preference learning and adaptation\n   ‚Ä¢ Seamless transitions between modalities\n\n2. Integration Patterns:\n   ‚Ä¢ Voice + visual: spoken commands with visual feedback\n   ‚Ä¢ Gesture + voice: natural hand movement with speech\n   ‚Ä¢ Text + visual: written input with graphical output\n   ‚Ä¢ Emotional + adaptive: mood-aware interface adjustment\n\n3. Technical Implementation:\n   ‚Ä¢ End-to-end multimodal learning with transformers\n   ‚Ä¢ Real-time context understanding and processing\n   ‚Ä¢ Conversational prosody beyond text-to-speech\n   ‚Ä¢ Cross-modal semantic alignment and consistency\n\nUser Experience: 95% natural interaction satisfaction'
  }
];