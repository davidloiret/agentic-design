import { PatternScenario } from './types';
import { nodeStyle, edgeStyle } from './styles';

export const confidenceVisualizationUIPattern: PatternScenario = {
  id: 'confidence-visualization-ui',
  title: 'Confidence Visualization UI Pattern',
  description: 'Visual representation of AI uncertainty and confidence levels using progress bars, color coding, and interactive displays achieving 82% improvement in appropriate AI reliance',
  initialNodes: [
    // AI trust challenge
    {
      id: 'ai-trust-challenge',
      position: { x: 400, y: 50 },
      data: { label: 'ü§î AI Trust Challenge\n"How to help users understand\nAI confidence levels and\nmake appropriate trust decisions?"' },
      style: { ...nodeStyle, background: '#f59e0b', minWidth: 320 },
    },

    // Confidence visualization framework
    {
      id: 'confidence-visualization-framework',
      position: { x: 400, y: 200 },
      data: { label: 'üìä Confidence Visualization Framework\n"Trust calibration:\n‚Ä¢ Uncertainty display\n‚Ä¢ Visual confidence meters\n‚Ä¢ Interactive exploration\n‚Ä¢ Transparency communication"' },
      style: { ...nodeStyle, background: '#06b6d4', minWidth: 290 },
    },

    // Uncertainty types
    {
      id: 'uncertainty-types',
      position: { x: 200, y: 350 },
      data: { label: 'üéØ Uncertainty Types\n"Spectrum approach:\n‚Ä¢ Parameter uncertainty\n‚Ä¢ Structural uncertainty\n‚Ä¢ Data uncertainty\n‚Ä¢ Computational uncertainty"' },
      style: { ...nodeStyle, background: '#8b5cf6', minWidth: 240 },
    },

    // Modern uncertainty theory
    {
      id: 'modern-uncertainty-theory',
      position: { x: 50, y: 500 },
      data: { label: 'üî¨ Modern Uncertainty Theory\n"2025 perspective:\n‚Ä¢ Beyond aleatoric/epistemic\n‚Ä¢ Spectrum of uncertainties\n‚Ä¢ Context-dependent\n‚Ä¢ Dynamic assessment"' },
      style: { ...nodeStyle, background: '#10b981', minWidth: 230 },
    },

    // Visual representations
    {
      id: 'visual-representations',
      position: { x: 600, y: 350 },
      data: { label: 'üé® Visual Representations\n"Display methods:\n‚Ä¢ Progress bars\n‚Ä¢ Gauge charts\n‚Ä¢ Distribution plots\n‚Ä¢ Badge systems"' },
      style: { ...nodeStyle, background: '#059669', minWidth: 220 },
    },

    // Color coding systems
    {
      id: 'color-coding-systems',
      position: { x: 750, y: 500 },
      data: { label: 'üåà Color Coding Systems\n"Trust communication:\n‚Ä¢ Green-yellow-red gradients\n‚Ä¢ Blue reliability scales\n‚Ä¢ WCAG 2.2 compliance\n‚Ä¢ Cultural sensitivity"' },
      style: { ...nodeStyle, background: '#f59e0b', minWidth: 230 },
    },

    // Trust calibration
    {
      id: 'trust-calibration',
      position: { x: 400, y: 650 },
      data: { label: 'ü§ù Trust Calibration\n"Appropriate reliance:\n‚Ä¢ 82% improvement rates\n‚Ä¢ Well-calibrated trust\n‚Ä¢ Overconfidence mitigation\n‚Ä¢ Capability understanding"' },
      style: { ...nodeStyle, background: '#8b5cf6', minWidth: 260 },
    },

    // Interactive exploration
    {
      id: 'interactive-exploration',
      position: { x: 200, y: 800 },
      data: { label: 'üîç Interactive Exploration\n"User control:\n‚Ä¢ Confidence drill-down\n‚Ä¢ Reasoning visualization\n‚Ä¢ Historical confidence\n‚Ä¢ Comparative analysis"' },
      style: { ...nodeStyle, background: '#10b981', minWidth: 240 },
    },

    // Real-time updates
    {
      id: 'real-time-updates',
      position: { x: 600, y: 800 },
      data: { label: '‚ö° Real-Time Updates\n"Dynamic display:\n‚Ä¢ Streaming confidence\n‚Ä¢ Evolution tracking\n‚Ä¢ Adaptive frequency\n‚Ä¢ Context awareness"' },
      style: { ...nodeStyle, background: '#ef4444', minWidth: 220 },
    },

    // Multi-modal design
    {
      id: 'multi-modal-design',
      position: { x: 200, y: 950 },
      data: { label: 'üé≠ Multi-Modal Design\n"Accessibility focus:\n‚Ä¢ Visual-audio-tactile\n‚Ä¢ Screen reader support\n‚Ä¢ Voice interface\n‚Ä¢ Haptic feedback"' },
      style: { ...nodeStyle, background: '#10b981', minWidth: 240 },
    },

    // Production implementations
    {
      id: 'production-implementations',
      position: { x: 600, y: 950 },
      data: { label: 'üè¢ Production Cases\n"Real-world success:\n‚Ä¢ Medical AI (78% threshold)\n‚Ä¢ Financial services\n‚Ä¢ Content generation\n‚Ä¢ 58% trust improvement"' },
      style: { ...nodeStyle, background: '#059669', minWidth: 240 },
    },

    // Design principles
    {
      id: 'design-principles',
      position: { x: 400, y: 1100 },
      data: { label: 'üìê Design Principles\n"Implementation guide:\n‚Ä¢ Transparency-first\n‚Ä¢ Progressive disclosure\n‚Ä¢ Contextual adaptation\n‚Ä¢ Continuous testing"' },
      style: { ...nodeStyle, background: '#8b5cf6', minWidth: 250 },
    },

    // Core visualization principle
    {
      id: 'visualization-principle',
      position: { x: 400, y: 1250 },
      data: { label: 'üéØ Confidence Visualization Principle\n"Visual uncertainty display achieves 82% improvement in appropriate AI reliance\nTrust calibration through transparency reduces overconfidence by 58%\nMulti-modal accessibility ensures inclusive confidence communication"' },
      style: { ...nodeStyle, background: '#06b6d4', minWidth: 420 },
    },
  ],
  initialEdges: [
    // Challenge addressed by framework
    {
      id: 'e1',
      source: 'ai-trust-challenge',
      target: 'confidence-visualization-framework',
      ...edgeStyle,
      label: 'solved by'
    },

    // Framework components
    {
      id: 'e2',
      source: 'confidence-visualization-framework',
      target: 'uncertainty-types',
      ...edgeStyle,
      label: 'identifies'
    },
    {
      id: 'e3',
      source: 'confidence-visualization-framework',
      target: 'visual-representations',
      ...edgeStyle,
      label: 'implements'
    },
    {
      id: 'e4',
      source: 'confidence-visualization-framework',
      target: 'trust-calibration',
      ...edgeStyle,
      label: 'enables'
    },

    // Uncertainty foundations
    {
      id: 'e5',
      source: 'uncertainty-types',
      target: 'modern-uncertainty-theory',
      ...edgeStyle,
      label: 'based on'
    },

    // Visual design
    {
      id: 'e6',
      source: 'visual-representations',
      target: 'color-coding-systems',
      ...edgeStyle,
      label: 'enhanced by'
    },

    // Trust mechanisms
    {
      id: 'e7',
      source: 'trust-calibration',
      target: 'interactive-exploration',
      ...edgeStyle,
      label: 'supports'
    },
    {
      id: 'e8',
      source: 'trust-calibration',
      target: 'real-time-updates',
      ...edgeStyle,
      label: 'requires'
    },

    // Cross-connections
    {
      id: 'e9',
      source: 'modern-uncertainty-theory',
      target: 'interactive-exploration',
      ...edgeStyle,
      label: 'informs'
    },
    {
      id: 'e10',
      source: 'color-coding-systems',
      target: 'real-time-updates',
      ...edgeStyle,
      label: 'applied in'
    },

    // Implementation flows
    {
      id: 'e11',
      source: 'interactive-exploration',
      target: 'multi-modal-design',
      ...edgeStyle,
      label: 'accessible via'
    },
    {
      id: 'e12',
      source: 'real-time-updates',
      target: 'production-implementations',
      ...edgeStyle,
      label: 'deployed in'
    },

    // Design and validation
    {
      id: 'e13',
      source: 'multi-modal-design',
      target: 'design-principles',
      ...edgeStyle,
      label: 'guided by'
    },
    {
      id: 'e14',
      source: 'production-implementations',
      target: 'design-principles',
      ...edgeStyle,
      label: 'validates'
    },

    // Principles prove effectiveness
    {
      id: 'e15',
      source: 'design-principles',
      target: 'visualization-principle',
      ...edgeStyle,
      label: 'demonstrates',
      style: { ...edgeStyle.style, strokeDasharray: '5,5' }
    },
  ],
  steps: [
    {
      title: "AI Trust Challenge",
      description: "How can users understand AI confidence levels and make appropriate trust decisions when AI systems provide varying degrees of certainty in their outputs?",
      activeNodes: ['ai-trust-challenge'],
      activeEdges: []
    },
    {
      title: "Confidence Visualization Framework",
      description: "Trust calibration framework addresses challenge through uncertainty display, visual confidence meters, interactive exploration tools, and transparent communication mechanisms.",
      activeNodes: ['confidence-visualization-framework'],
      activeEdges: ['e1']
    },
    {
      title: "Uncertainty Types and Visual Design",
      description: "Modern 2025 approach recognizes spectrum of uncertainties beyond traditional categories. Visual representations include progress bars, gauge charts, distribution plots with WCAG-compliant color coding.",
      activeNodes: ['uncertainty-types', 'modern-uncertainty-theory', 'visual-representations', 'color-coding-systems'],
      activeEdges: ['e2', 'e3', 'e5', 'e6']
    },
    {
      title: "Trust Calibration and Interaction",
      description: "Achieves 82% improvement in appropriate AI reliance through well-calibrated trust. Interactive exploration enables confidence drill-down while real-time updates show dynamic confidence evolution.",
      activeNodes: ['trust-calibration', 'interactive-exploration', 'real-time-updates'],
      activeEdges: ['e4', 'e7', 'e8', 'e9', 'e10']
    },
    {
      title: "Accessibility and Production Success",
      description: "Multi-modal design ensures visual-audio-tactile accessibility. Production implementations in medical AI, financial services achieve 58% trust improvement with 78% confidence thresholds.",
      activeNodes: ['multi-modal-design', 'production-implementations'],
      activeEdges: ['e11', 'e12']
    },
    {
      title: "Design Principles and Validation",
      description: "Transparency-first design with progressive disclosure and contextual adaptation. Visual uncertainty display with trust calibration creates inclusive confidence communication for appropriate AI reliance.",
      activeNodes: ['design-principles', 'visualization-principle'],
      activeEdges: ['e13', 'e14', 'e15']
    }
  ]
};